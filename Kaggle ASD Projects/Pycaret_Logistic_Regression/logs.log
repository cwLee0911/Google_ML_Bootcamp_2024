2024-07-30 23:22:25,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-30 23:22:25,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-30 23:22:25,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-30 23:22:25,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-30 23:27:51,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-30 23:27:51,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-30 23:27:51,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-30 23:27:51,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-30 23:27:51,683:INFO:PyCaret ClassificationExperiment
2024-07-30 23:27:51,683:INFO:Logging name: clf-default-name
2024-07-30 23:27:51,683:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-30 23:27:51,683:INFO:version 3.3.2
2024-07-30 23:27:51,683:INFO:Initializing setup()
2024-07-30 23:27:51,683:INFO:self.USI: 1e07
2024-07-30 23:27:51,683:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'idx', 'pipeline', 'html_param', '_available_plots', 'y_train', '_ml_usecase', 'X_test', 'gpu_param', 'X', 'log_plots_param', 'logging_param', 'n_jobs_param', 'fold_shuffle_param', 'fold_groups_param', 'y_test', 'y', 'exp_id', 'target_param', 'data', 'fix_imbalance', 'memory', 'gpu_n_jobs_param', 'is_multiclass', 'USI', 'fold_generator', 'seed'}
2024-07-30 23:27:51,683:INFO:Checking environment
2024-07-30 23:27:51,683:INFO:python_version: 3.9.6
2024-07-30 23:27:51,683:INFO:python_build: ('default', 'Feb  3 2024 15:58:27')
2024-07-30 23:27:51,683:INFO:machine: arm64
2024-07-30 23:27:51,683:INFO:platform: macOS-14.4-arm64-arm-64bit
2024-07-30 23:27:51,684:INFO:Memory: svmem(total=38654705664, available=18863112192, percent=51.2, used=18850971648, free=2952151040, active=15925706752, inactive=13079396352, wired=2925264896)
2024-07-30 23:27:51,684:INFO:Physical Core: 14
2024-07-30 23:27:51,684:INFO:Logical Core: 14
2024-07-30 23:27:51,684:INFO:Checking libraries
2024-07-30 23:27:51,684:INFO:System:
2024-07-30 23:27:51,684:INFO:    python: 3.9.6 (default, Feb  3 2024, 15:58:27)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-07-30 23:27:51,684:INFO:executable: /Library/Developer/CommandLineTools/usr/bin/python3
2024-07-30 23:27:51,684:INFO:   machine: macOS-14.4-arm64-arm-64bit
2024-07-30 23:27:51,684:INFO:PyCaret required dependencies:
2024-07-30 23:27:52,132:INFO:                 pip: 21.2.4
2024-07-30 23:27:52,132:INFO:          setuptools: 58.0.4
2024-07-30 23:27:52,132:INFO:             pycaret: 3.3.2
2024-07-30 23:27:52,132:INFO:             IPython: 8.18.1
2024-07-30 23:27:52,132:INFO:          ipywidgets: 7.8.3
2024-07-30 23:27:52,132:INFO:                tqdm: 4.66.4
2024-07-30 23:27:52,132:INFO:               numpy: 1.23.5
2024-07-30 23:27:52,132:INFO:              pandas: 2.0.3
2024-07-30 23:27:52,132:INFO:              jinja2: 3.1.4
2024-07-30 23:27:52,132:INFO:               scipy: 1.10.1
2024-07-30 23:27:52,132:INFO:              joblib: 1.3.2
2024-07-30 23:27:52,132:INFO:             sklearn: 1.4.2
2024-07-30 23:27:52,132:INFO:                pyod: 2.0.1
2024-07-30 23:27:52,132:INFO:            imblearn: 0.12.3
2024-07-30 23:27:52,132:INFO:   category_encoders: 2.6.3
2024-07-30 23:27:52,132:INFO:            lightgbm: 4.4.0
2024-07-30 23:27:52,132:INFO:               numba: 0.58.1
2024-07-30 23:27:52,132:INFO:            requests: 2.32.3
2024-07-30 23:27:52,132:INFO:          matplotlib: 3.7.3
2024-07-30 23:27:52,132:INFO:          scikitplot: 0.3.7
2024-07-30 23:27:52,133:INFO:         yellowbrick: 1.5
2024-07-30 23:27:52,133:INFO:              plotly: 5.23.0
2024-07-30 23:27:52,133:INFO:    plotly-resampler: Not installed
2024-07-30 23:27:52,133:INFO:             kaleido: 0.2.1
2024-07-30 23:27:52,133:INFO:           schemdraw: 0.15
2024-07-30 23:27:52,133:INFO:         statsmodels: 0.14.2
2024-07-30 23:27:52,133:INFO:              sktime: 0.26.0
2024-07-30 23:27:52,133:INFO:               tbats: 1.1.3
2024-07-30 23:27:52,133:INFO:            pmdarima: 2.0.4
2024-07-30 23:27:52,133:INFO:              psutil: 6.0.0
2024-07-30 23:27:52,133:INFO:          markupsafe: 2.1.5
2024-07-30 23:27:52,133:INFO:             pickle5: Not installed
2024-07-30 23:27:52,133:INFO:         cloudpickle: 2.2.1
2024-07-30 23:27:52,133:INFO:         deprecation: 2.1.0
2024-07-30 23:27:52,133:INFO:              xxhash: 3.4.1
2024-07-30 23:27:52,133:INFO:           wurlitzer: 3.1.1
2024-07-30 23:27:52,133:INFO:PyCaret optional dependencies:
2024-07-30 23:27:52,608:INFO:                shap: 0.44.1
2024-07-30 23:27:52,608:INFO:           interpret: 0.6.2
2024-07-30 23:27:52,608:INFO:                umap: 0.5.6
2024-07-30 23:27:52,608:INFO:     ydata_profiling: 4.6.0
2024-07-30 23:27:52,608:INFO:  explainerdashboard: 0.4.7
2024-07-30 23:27:52,608:INFO:             autoviz: 0.1.902
2024-07-30 23:27:52,608:INFO:           fairlearn: 0.7.0
2024-07-30 23:27:52,608:INFO:          deepchecks: 0.18.1
2024-07-30 23:27:52,608:INFO:             xgboost: 1.6.2
2024-07-30 23:27:52,608:INFO:            catboost: 1.1.1
2024-07-30 23:27:52,608:INFO:              kmodes: 0.12.2
2024-07-30 23:27:52,608:INFO:             mlxtend: 0.23.1
2024-07-30 23:27:52,608:INFO:       statsforecast: 1.5.0
2024-07-30 23:27:52,608:INFO:        tune_sklearn: 0.1.5
2024-07-30 23:27:52,608:INFO:                 ray: 2.33.0
2024-07-30 23:27:52,608:INFO:            hyperopt: 0.2.7
2024-07-30 23:27:52,608:INFO:              optuna: 3.6.1
2024-07-30 23:27:52,608:INFO:               skopt: 0.10.2
2024-07-30 23:27:52,608:INFO:              mlflow: 2.15.0
2024-07-30 23:27:52,608:INFO:              gradio: 3.50.2
2024-07-30 23:27:52,608:INFO:             fastapi: 0.111.1
2024-07-30 23:27:52,608:INFO:             uvicorn: 0.30.3
2024-07-30 23:27:52,608:INFO:              m2cgen: 0.10.0
2024-07-30 23:27:52,608:INFO:           evidently: 0.4.32
2024-07-30 23:27:52,608:INFO:               fugue: 0.8.7
2024-07-30 23:27:52,608:INFO:           streamlit: Not installed
2024-07-30 23:27:52,608:INFO:             prophet: Not installed
2024-07-30 23:27:52,608:INFO:None
2024-07-30 23:27:52,608:INFO:Set up data.
2024-07-30 23:27:52,613:INFO:Set up folding strategy.
2024-07-30 23:27:52,613:INFO:Set up train/test split.
2024-07-30 23:27:52,616:INFO:Set up index.
2024-07-30 23:27:52,616:INFO:Assigning column types.
2024-07-30 23:27:52,618:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-30 23:27:52,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-30 23:27:52,637:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-30 23:27:52,650:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-30 23:27:52,660:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-30 23:27:52,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-30 23:27:52,695:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-30 23:27:52,706:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-30 23:27:52,707:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-30 23:27:52,707:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-30 23:27:52,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-30 23:27:52,735:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-30 23:27:52,736:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-30 23:27:52,753:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-30 23:27:52,764:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-30 23:27:52,765:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-30 23:27:52,765:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-30 23:27:52,792:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-30 23:27:52,793:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-30 23:27:52,821:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-30 23:27:52,822:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-30 23:27:52,823:INFO:Preparing preprocessing pipeline...
2024-07-30 23:27:52,824:INFO:Set up simple imputation.
2024-07-30 23:27:52,826:INFO:Set up encoding of ordinal features.
2024-07-30 23:27:52,826:INFO:Set up encoding of categorical features.
2024-07-30 23:27:52,827:INFO:Set up column name cleaning.
2024-07-30 23:27:52,861:INFO:Finished creating preprocessing pipeline.
2024-07-30 23:27:52,869:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/4f/9jwcfl7s6sz9pnhpf52ybf500000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=Simple...
                 TransformerWrapper(exclude=None, include=['ethnicity'],
                                    transformer=OneHotEncoder(cols=['ethnicity'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-07-30 23:27:52,869:INFO:Creating final display dataframe.
2024-07-30 23:27:52,971:INFO:Setup _display_container:                     Description             Value
0                    Session id              2110
1                        Target         Class/ASD
2                   Target type            Binary
3           Original data shape         (114, 29)
4        Transformed data shape         (114, 29)
5   Transformed train set shape          (79, 29)
6    Transformed test set shape          (35, 29)
7              Numeric features                26
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              1e07
2024-07-30 23:27:53,000:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-30 23:27:53,002:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-30 23:27:53,030:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-30 23:27:53,031:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-30 23:27:53,032:INFO:setup() successfully completed in 1.35s...............
2024-07-30 23:28:15,417:INFO:Initializing compare_models()
2024-07-30 23:28:15,417:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-07-30 23:28:15,417:INFO:Checking exceptions
2024-07-30 23:28:15,422:INFO:Preparing display monitor
2024-07-30 23:28:15,452:INFO:Initializing Logistic Regression
2024-07-30 23:28:15,452:INFO:Total runtime is 3.417332967122396e-06 minutes
2024-07-30 23:28:15,454:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:15,454:INFO:Initializing create_model()
2024-07-30 23:28:15,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:15,454:INFO:Checking exceptions
2024-07-30 23:28:15,454:INFO:Importing libraries
2024-07-30 23:28:15,454:INFO:Copying training dataset
2024-07-30 23:28:15,458:INFO:Defining folds
2024-07-30 23:28:15,458:INFO:Declaring metric variables
2024-07-30 23:28:15,459:INFO:Importing untrained model
2024-07-30 23:28:15,461:INFO:Logistic Regression Imported successfully
2024-07-30 23:28:15,465:INFO:Starting cross validation
2024-07-30 23:28:15,466:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:17,726:INFO:Calculating mean and std
2024-07-30 23:28:17,727:INFO:Creating metrics dataframe
2024-07-30 23:28:17,729:INFO:Uploading results into container
2024-07-30 23:28:17,729:INFO:Uploading model into container now
2024-07-30 23:28:17,729:INFO:_master_model_container: 1
2024-07-30 23:28:17,730:INFO:_display_container: 2
2024-07-30 23:28:17,730:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-30 23:28:17,730:INFO:create_model() successfully completed......................................
2024-07-30 23:28:17,795:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:17,795:INFO:Creating metrics dataframe
2024-07-30 23:28:17,798:INFO:Initializing K Neighbors Classifier
2024-07-30 23:28:17,798:INFO:Total runtime is 0.03910033305486044 minutes
2024-07-30 23:28:17,800:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:17,800:INFO:Initializing create_model()
2024-07-30 23:28:17,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:17,800:INFO:Checking exceptions
2024-07-30 23:28:17,800:INFO:Importing libraries
2024-07-30 23:28:17,800:INFO:Copying training dataset
2024-07-30 23:28:17,803:INFO:Defining folds
2024-07-30 23:28:17,803:INFO:Declaring metric variables
2024-07-30 23:28:17,804:INFO:Importing untrained model
2024-07-30 23:28:17,805:INFO:K Neighbors Classifier Imported successfully
2024-07-30 23:28:17,808:INFO:Starting cross validation
2024-07-30 23:28:17,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:18,903:INFO:Calculating mean and std
2024-07-30 23:28:18,904:INFO:Creating metrics dataframe
2024-07-30 23:28:18,905:INFO:Uploading results into container
2024-07-30 23:28:18,905:INFO:Uploading model into container now
2024-07-30 23:28:18,905:INFO:_master_model_container: 2
2024-07-30 23:28:18,905:INFO:_display_container: 2
2024-07-30 23:28:18,906:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-30 23:28:18,906:INFO:create_model() successfully completed......................................
2024-07-30 23:28:18,964:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:18,964:INFO:Creating metrics dataframe
2024-07-30 23:28:18,967:INFO:Initializing Naive Bayes
2024-07-30 23:28:18,967:INFO:Total runtime is 0.05859185059865316 minutes
2024-07-30 23:28:18,969:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:18,969:INFO:Initializing create_model()
2024-07-30 23:28:18,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:18,969:INFO:Checking exceptions
2024-07-30 23:28:18,969:INFO:Importing libraries
2024-07-30 23:28:18,969:INFO:Copying training dataset
2024-07-30 23:28:18,972:INFO:Defining folds
2024-07-30 23:28:18,972:INFO:Declaring metric variables
2024-07-30 23:28:18,973:INFO:Importing untrained model
2024-07-30 23:28:18,975:INFO:Naive Bayes Imported successfully
2024-07-30 23:28:18,978:INFO:Starting cross validation
2024-07-30 23:28:18,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:20,096:INFO:Calculating mean and std
2024-07-30 23:28:20,097:INFO:Creating metrics dataframe
2024-07-30 23:28:20,098:INFO:Uploading results into container
2024-07-30 23:28:20,098:INFO:Uploading model into container now
2024-07-30 23:28:20,099:INFO:_master_model_container: 3
2024-07-30 23:28:20,099:INFO:_display_container: 2
2024-07-30 23:28:20,099:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-30 23:28:20,099:INFO:create_model() successfully completed......................................
2024-07-30 23:28:20,162:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:20,162:INFO:Creating metrics dataframe
2024-07-30 23:28:20,166:INFO:Initializing Decision Tree Classifier
2024-07-30 23:28:20,166:INFO:Total runtime is 0.0785693645477295 minutes
2024-07-30 23:28:20,168:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:20,168:INFO:Initializing create_model()
2024-07-30 23:28:20,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:20,168:INFO:Checking exceptions
2024-07-30 23:28:20,168:INFO:Importing libraries
2024-07-30 23:28:20,168:INFO:Copying training dataset
2024-07-30 23:28:20,171:INFO:Defining folds
2024-07-30 23:28:20,172:INFO:Declaring metric variables
2024-07-30 23:28:20,173:INFO:Importing untrained model
2024-07-30 23:28:20,175:INFO:Decision Tree Classifier Imported successfully
2024-07-30 23:28:20,181:INFO:Starting cross validation
2024-07-30 23:28:20,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:20,253:INFO:Calculating mean and std
2024-07-30 23:28:20,254:INFO:Creating metrics dataframe
2024-07-30 23:28:20,255:INFO:Uploading results into container
2024-07-30 23:28:20,255:INFO:Uploading model into container now
2024-07-30 23:28:20,256:INFO:_master_model_container: 4
2024-07-30 23:28:20,256:INFO:_display_container: 2
2024-07-30 23:28:20,256:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2110, splitter='best')
2024-07-30 23:28:20,256:INFO:create_model() successfully completed......................................
2024-07-30 23:28:20,316:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:20,317:INFO:Creating metrics dataframe
2024-07-30 23:28:20,320:INFO:Initializing SVM - Linear Kernel
2024-07-30 23:28:20,321:INFO:Total runtime is 0.08114304542541505 minutes
2024-07-30 23:28:20,322:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:20,322:INFO:Initializing create_model()
2024-07-30 23:28:20,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:20,322:INFO:Checking exceptions
2024-07-30 23:28:20,322:INFO:Importing libraries
2024-07-30 23:28:20,322:INFO:Copying training dataset
2024-07-30 23:28:20,325:INFO:Defining folds
2024-07-30 23:28:20,325:INFO:Declaring metric variables
2024-07-30 23:28:20,327:INFO:Importing untrained model
2024-07-30 23:28:20,329:INFO:SVM - Linear Kernel Imported successfully
2024-07-30 23:28:20,332:INFO:Starting cross validation
2024-07-30 23:28:20,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:20,401:INFO:Calculating mean and std
2024-07-30 23:28:20,401:INFO:Creating metrics dataframe
2024-07-30 23:28:20,403:INFO:Uploading results into container
2024-07-30 23:28:20,403:INFO:Uploading model into container now
2024-07-30 23:28:20,403:INFO:_master_model_container: 5
2024-07-30 23:28:20,403:INFO:_display_container: 2
2024-07-30 23:28:20,403:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2110, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-30 23:28:20,404:INFO:create_model() successfully completed......................................
2024-07-30 23:28:20,465:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:20,465:INFO:Creating metrics dataframe
2024-07-30 23:28:20,468:INFO:Initializing Ridge Classifier
2024-07-30 23:28:20,468:INFO:Total runtime is 0.0836050311724345 minutes
2024-07-30 23:28:20,470:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:20,470:INFO:Initializing create_model()
2024-07-30 23:28:20,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:20,471:INFO:Checking exceptions
2024-07-30 23:28:20,471:INFO:Importing libraries
2024-07-30 23:28:20,471:INFO:Copying training dataset
2024-07-30 23:28:20,474:INFO:Defining folds
2024-07-30 23:28:20,474:INFO:Declaring metric variables
2024-07-30 23:28:20,475:INFO:Importing untrained model
2024-07-30 23:28:20,476:INFO:Ridge Classifier Imported successfully
2024-07-30 23:28:20,480:INFO:Starting cross validation
2024-07-30 23:28:20,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:20,552:INFO:Calculating mean and std
2024-07-30 23:28:20,553:INFO:Creating metrics dataframe
2024-07-30 23:28:20,554:INFO:Uploading results into container
2024-07-30 23:28:20,554:INFO:Uploading model into container now
2024-07-30 23:28:20,554:INFO:_master_model_container: 6
2024-07-30 23:28:20,554:INFO:_display_container: 2
2024-07-30 23:28:20,555:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2110, solver='auto',
                tol=0.0001)
2024-07-30 23:28:20,555:INFO:create_model() successfully completed......................................
2024-07-30 23:28:20,611:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:20,611:INFO:Creating metrics dataframe
2024-07-30 23:28:20,615:INFO:Initializing Random Forest Classifier
2024-07-30 23:28:20,616:INFO:Total runtime is 0.08605877955754598 minutes
2024-07-30 23:28:20,617:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:20,617:INFO:Initializing create_model()
2024-07-30 23:28:20,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:20,617:INFO:Checking exceptions
2024-07-30 23:28:20,617:INFO:Importing libraries
2024-07-30 23:28:20,617:INFO:Copying training dataset
2024-07-30 23:28:20,620:INFO:Defining folds
2024-07-30 23:28:20,620:INFO:Declaring metric variables
2024-07-30 23:28:20,621:INFO:Importing untrained model
2024-07-30 23:28:20,623:INFO:Random Forest Classifier Imported successfully
2024-07-30 23:28:20,625:INFO:Starting cross validation
2024-07-30 23:28:20,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:20,820:INFO:Calculating mean and std
2024-07-30 23:28:20,821:INFO:Creating metrics dataframe
2024-07-30 23:28:20,822:INFO:Uploading results into container
2024-07-30 23:28:20,822:INFO:Uploading model into container now
2024-07-30 23:28:20,822:INFO:_master_model_container: 7
2024-07-30 23:28:20,822:INFO:_display_container: 2
2024-07-30 23:28:20,822:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2110, verbose=0,
                       warm_start=False)
2024-07-30 23:28:20,822:INFO:create_model() successfully completed......................................
2024-07-30 23:28:20,886:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:20,886:INFO:Creating metrics dataframe
2024-07-30 23:28:20,890:INFO:Initializing Quadratic Discriminant Analysis
2024-07-30 23:28:20,890:INFO:Total runtime is 0.09064113299051921 minutes
2024-07-30 23:28:20,892:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:20,892:INFO:Initializing create_model()
2024-07-30 23:28:20,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:20,893:INFO:Checking exceptions
2024-07-30 23:28:20,893:INFO:Importing libraries
2024-07-30 23:28:20,893:INFO:Copying training dataset
2024-07-30 23:28:20,896:INFO:Defining folds
2024-07-30 23:28:20,896:INFO:Declaring metric variables
2024-07-30 23:28:20,897:INFO:Importing untrained model
2024-07-30 23:28:20,898:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-30 23:28:20,901:INFO:Starting cross validation
2024-07-30 23:28:20,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:20,934:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,935:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,936:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,936:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,937:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,942:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,943:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,944:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,944:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,944:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,944:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,944:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,944:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,945:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,946:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,946:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,946:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,946:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,946:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,946:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,947:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,947:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,947:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,947:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,947:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,948:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,948:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,948:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,952:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,952:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,952:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,952:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,952:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,952:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,953:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-30 23:28:20,953:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,953:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,953:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,953:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,953:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,953:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,955:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,955:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,955:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,955:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,956:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,956:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,956:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,956:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,957:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,957:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,957:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,957:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,957:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,957:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,958:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,958:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,958:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,958:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,958:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,958:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,958:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,960:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,961:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,961:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,962:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,962:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,962:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,963:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,963:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-30 23:28:20,963:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-30 23:28:20,964:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,964:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,964:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,965:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,967:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,968:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,970:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-30 23:28:20,972:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-30 23:28:20,978:INFO:Calculating mean and std
2024-07-30 23:28:20,978:INFO:Creating metrics dataframe
2024-07-30 23:28:20,979:INFO:Uploading results into container
2024-07-30 23:28:20,980:INFO:Uploading model into container now
2024-07-30 23:28:20,980:INFO:_master_model_container: 8
2024-07-30 23:28:20,980:INFO:_display_container: 2
2024-07-30 23:28:20,980:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-30 23:28:20,980:INFO:create_model() successfully completed......................................
2024-07-30 23:28:21,040:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:21,040:INFO:Creating metrics dataframe
2024-07-30 23:28:21,045:INFO:Initializing Ada Boost Classifier
2024-07-30 23:28:21,045:INFO:Total runtime is 0.0932161808013916 minutes
2024-07-30 23:28:21,046:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:21,047:INFO:Initializing create_model()
2024-07-30 23:28:21,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:21,047:INFO:Checking exceptions
2024-07-30 23:28:21,047:INFO:Importing libraries
2024-07-30 23:28:21,047:INFO:Copying training dataset
2024-07-30 23:28:21,049:INFO:Defining folds
2024-07-30 23:28:21,049:INFO:Declaring metric variables
2024-07-30 23:28:21,051:INFO:Importing untrained model
2024-07-30 23:28:21,053:INFO:Ada Boost Classifier Imported successfully
2024-07-30 23:28:21,056:INFO:Starting cross validation
2024-07-30 23:28:21,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:21,084:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,084:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,086:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,091:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,092:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,093:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,094:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,094:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,097:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,101:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-30 23:28:21,147:INFO:Calculating mean and std
2024-07-30 23:28:21,148:INFO:Creating metrics dataframe
2024-07-30 23:28:21,148:INFO:Uploading results into container
2024-07-30 23:28:21,149:INFO:Uploading model into container now
2024-07-30 23:28:21,149:INFO:_master_model_container: 9
2024-07-30 23:28:21,149:INFO:_display_container: 2
2024-07-30 23:28:21,149:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2110)
2024-07-30 23:28:21,150:INFO:create_model() successfully completed......................................
2024-07-30 23:28:21,213:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:21,213:INFO:Creating metrics dataframe
2024-07-30 23:28:21,217:INFO:Initializing Gradient Boosting Classifier
2024-07-30 23:28:21,217:INFO:Total runtime is 0.0960793654123942 minutes
2024-07-30 23:28:21,218:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:21,218:INFO:Initializing create_model()
2024-07-30 23:28:21,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:21,218:INFO:Checking exceptions
2024-07-30 23:28:21,218:INFO:Importing libraries
2024-07-30 23:28:21,218:INFO:Copying training dataset
2024-07-30 23:28:21,222:INFO:Defining folds
2024-07-30 23:28:21,222:INFO:Declaring metric variables
2024-07-30 23:28:21,223:INFO:Importing untrained model
2024-07-30 23:28:21,225:INFO:Gradient Boosting Classifier Imported successfully
2024-07-30 23:28:21,227:INFO:Starting cross validation
2024-07-30 23:28:21,228:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:21,318:INFO:Calculating mean and std
2024-07-30 23:28:21,318:INFO:Creating metrics dataframe
2024-07-30 23:28:21,319:INFO:Uploading results into container
2024-07-30 23:28:21,319:INFO:Uploading model into container now
2024-07-30 23:28:21,320:INFO:_master_model_container: 10
2024-07-30 23:28:21,320:INFO:_display_container: 2
2024-07-30 23:28:21,320:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2110, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-30 23:28:21,320:INFO:create_model() successfully completed......................................
2024-07-30 23:28:21,379:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:21,379:INFO:Creating metrics dataframe
2024-07-30 23:28:21,383:INFO:Initializing Linear Discriminant Analysis
2024-07-30 23:28:21,383:INFO:Total runtime is 0.09884906609853109 minutes
2024-07-30 23:28:21,384:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:21,385:INFO:Initializing create_model()
2024-07-30 23:28:21,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:21,385:INFO:Checking exceptions
2024-07-30 23:28:21,385:INFO:Importing libraries
2024-07-30 23:28:21,385:INFO:Copying training dataset
2024-07-30 23:28:21,388:INFO:Defining folds
2024-07-30 23:28:21,388:INFO:Declaring metric variables
2024-07-30 23:28:21,389:INFO:Importing untrained model
2024-07-30 23:28:21,391:INFO:Linear Discriminant Analysis Imported successfully
2024-07-30 23:28:21,393:INFO:Starting cross validation
2024-07-30 23:28:21,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:21,462:INFO:Calculating mean and std
2024-07-30 23:28:21,463:INFO:Creating metrics dataframe
2024-07-30 23:28:21,464:INFO:Uploading results into container
2024-07-30 23:28:21,464:INFO:Uploading model into container now
2024-07-30 23:28:21,465:INFO:_master_model_container: 11
2024-07-30 23:28:21,465:INFO:_display_container: 2
2024-07-30 23:28:21,465:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-30 23:28:21,465:INFO:create_model() successfully completed......................................
2024-07-30 23:28:21,527:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:21,527:INFO:Creating metrics dataframe
2024-07-30 23:28:21,531:INFO:Initializing Extra Trees Classifier
2024-07-30 23:28:21,531:INFO:Total runtime is 0.10131973425547282 minutes
2024-07-30 23:28:21,533:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:21,533:INFO:Initializing create_model()
2024-07-30 23:28:21,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:21,533:INFO:Checking exceptions
2024-07-30 23:28:21,533:INFO:Importing libraries
2024-07-30 23:28:21,533:INFO:Copying training dataset
2024-07-30 23:28:21,536:INFO:Defining folds
2024-07-30 23:28:21,536:INFO:Declaring metric variables
2024-07-30 23:28:21,538:INFO:Importing untrained model
2024-07-30 23:28:21,539:INFO:Extra Trees Classifier Imported successfully
2024-07-30 23:28:21,542:INFO:Starting cross validation
2024-07-30 23:28:21,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:21,720:INFO:Calculating mean and std
2024-07-30 23:28:21,720:INFO:Creating metrics dataframe
2024-07-30 23:28:21,721:INFO:Uploading results into container
2024-07-30 23:28:21,721:INFO:Uploading model into container now
2024-07-30 23:28:21,722:INFO:_master_model_container: 12
2024-07-30 23:28:21,722:INFO:_display_container: 2
2024-07-30 23:28:21,722:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2110, verbose=0,
                     warm_start=False)
2024-07-30 23:28:21,722:INFO:create_model() successfully completed......................................
2024-07-30 23:28:21,776:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:21,776:INFO:Creating metrics dataframe
2024-07-30 23:28:21,781:INFO:Initializing Extreme Gradient Boosting
2024-07-30 23:28:21,781:INFO:Total runtime is 0.10548871358235677 minutes
2024-07-30 23:28:21,783:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:21,783:INFO:Initializing create_model()
2024-07-30 23:28:21,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:21,783:INFO:Checking exceptions
2024-07-30 23:28:21,783:INFO:Importing libraries
2024-07-30 23:28:21,783:INFO:Copying training dataset
2024-07-30 23:28:21,786:INFO:Defining folds
2024-07-30 23:28:21,786:INFO:Declaring metric variables
2024-07-30 23:28:21,788:INFO:Importing untrained model
2024-07-30 23:28:21,789:INFO:Extreme Gradient Boosting Imported successfully
2024-07-30 23:28:21,792:INFO:Starting cross validation
2024-07-30 23:28:21,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:21,993:INFO:Calculating mean and std
2024-07-30 23:28:21,993:INFO:Creating metrics dataframe
2024-07-30 23:28:21,994:INFO:Uploading results into container
2024-07-30 23:28:21,995:INFO:Uploading model into container now
2024-07-30 23:28:21,995:INFO:_master_model_container: 13
2024-07-30 23:28:21,995:INFO:_display_container: 2
2024-07-30 23:28:21,995:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=2110, reg_alpha=None, ...)
2024-07-30 23:28:21,995:INFO:create_model() successfully completed......................................
2024-07-30 23:28:22,056:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:22,056:INFO:Creating metrics dataframe
2024-07-30 23:28:22,061:INFO:Initializing Light Gradient Boosting Machine
2024-07-30 23:28:22,061:INFO:Total runtime is 0.11014683246612549 minutes
2024-07-30 23:28:22,062:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:22,062:INFO:Initializing create_model()
2024-07-30 23:28:22,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:22,062:INFO:Checking exceptions
2024-07-30 23:28:22,062:INFO:Importing libraries
2024-07-30 23:28:22,062:INFO:Copying training dataset
2024-07-30 23:28:22,065:INFO:Defining folds
2024-07-30 23:28:22,065:INFO:Declaring metric variables
2024-07-30 23:28:22,066:INFO:Importing untrained model
2024-07-30 23:28:22,068:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-30 23:28:22,070:INFO:Starting cross validation
2024-07-30 23:28:22,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:22,652:INFO:Calculating mean and std
2024-07-30 23:28:22,653:INFO:Creating metrics dataframe
2024-07-30 23:28:22,654:INFO:Uploading results into container
2024-07-30 23:28:22,654:INFO:Uploading model into container now
2024-07-30 23:28:22,654:INFO:_master_model_container: 14
2024-07-30 23:28:22,654:INFO:_display_container: 2
2024-07-30 23:28:22,654:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2110, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-30 23:28:22,654:INFO:create_model() successfully completed......................................
2024-07-30 23:28:22,712:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:22,712:INFO:Creating metrics dataframe
2024-07-30 23:28:22,716:INFO:Initializing CatBoost Classifier
2024-07-30 23:28:22,716:INFO:Total runtime is 0.12107343276341756 minutes
2024-07-30 23:28:22,718:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:22,718:INFO:Initializing create_model()
2024-07-30 23:28:22,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:22,718:INFO:Checking exceptions
2024-07-30 23:28:22,718:INFO:Importing libraries
2024-07-30 23:28:22,718:INFO:Copying training dataset
2024-07-30 23:28:22,721:INFO:Defining folds
2024-07-30 23:28:22,721:INFO:Declaring metric variables
2024-07-30 23:28:22,722:INFO:Importing untrained model
2024-07-30 23:28:22,724:INFO:CatBoost Classifier Imported successfully
2024-07-30 23:28:22,726:INFO:Starting cross validation
2024-07-30 23:28:22,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:24,609:INFO:Calculating mean and std
2024-07-30 23:28:24,610:INFO:Creating metrics dataframe
2024-07-30 23:28:24,611:INFO:Uploading results into container
2024-07-30 23:28:24,611:INFO:Uploading model into container now
2024-07-30 23:28:24,611:INFO:_master_model_container: 15
2024-07-30 23:28:24,611:INFO:_display_container: 2
2024-07-30 23:28:24,611:INFO:<catboost.core.CatBoostClassifier object at 0x352b4f5e0>
2024-07-30 23:28:24,611:INFO:create_model() successfully completed......................................
2024-07-30 23:28:24,671:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:24,672:INFO:Creating metrics dataframe
2024-07-30 23:28:24,677:INFO:Initializing Dummy Classifier
2024-07-30 23:28:24,677:INFO:Total runtime is 0.15375821590423583 minutes
2024-07-30 23:28:24,679:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:24,679:INFO:Initializing create_model()
2024-07-30 23:28:24,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1434f92b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:24,679:INFO:Checking exceptions
2024-07-30 23:28:24,679:INFO:Importing libraries
2024-07-30 23:28:24,679:INFO:Copying training dataset
2024-07-30 23:28:24,682:INFO:Defining folds
2024-07-30 23:28:24,682:INFO:Declaring metric variables
2024-07-30 23:28:24,683:INFO:Importing untrained model
2024-07-30 23:28:24,685:INFO:Dummy Classifier Imported successfully
2024-07-30 23:28:24,688:INFO:Starting cross validation
2024-07-30 23:28:24,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:24,743:INFO:Calculating mean and std
2024-07-30 23:28:24,744:INFO:Creating metrics dataframe
2024-07-30 23:28:24,745:INFO:Uploading results into container
2024-07-30 23:28:24,745:INFO:Uploading model into container now
2024-07-30 23:28:24,745:INFO:_master_model_container: 16
2024-07-30 23:28:24,745:INFO:_display_container: 2
2024-07-30 23:28:24,746:INFO:DummyClassifier(constant=None, random_state=2110, strategy='prior')
2024-07-30 23:28:24,746:INFO:create_model() successfully completed......................................
2024-07-30 23:28:24,803:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:24,803:INFO:Creating metrics dataframe
2024-07-30 23:28:24,811:INFO:Initializing create_model()
2024-07-30 23:28:24,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:24,811:INFO:Checking exceptions
2024-07-30 23:28:24,812:INFO:Importing libraries
2024-07-30 23:28:24,812:INFO:Copying training dataset
2024-07-30 23:28:24,815:INFO:Defining folds
2024-07-30 23:28:24,815:INFO:Declaring metric variables
2024-07-30 23:28:24,815:INFO:Importing untrained model
2024-07-30 23:28:24,815:INFO:Declaring custom model
2024-07-30 23:28:24,815:INFO:Naive Bayes Imported successfully
2024-07-30 23:28:24,816:INFO:Cross validation set to False
2024-07-30 23:28:24,816:INFO:Fitting Model
2024-07-30 23:28:24,833:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-30 23:28:24,833:INFO:create_model() successfully completed......................................
2024-07-30 23:28:24,905:INFO:_master_model_container: 16
2024-07-30 23:28:24,905:INFO:_display_container: 2
2024-07-30 23:28:24,905:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-30 23:28:24,906:INFO:compare_models() successfully completed......................................
2024-07-30 23:28:24,906:INFO:Initializing create_model()
2024-07-30 23:28:24,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:24,906:INFO:Checking exceptions
2024-07-30 23:28:24,912:INFO:Importing libraries
2024-07-30 23:28:24,913:INFO:Copying training dataset
2024-07-30 23:28:24,916:INFO:Defining folds
2024-07-30 23:28:24,916:INFO:Declaring metric variables
2024-07-30 23:28:24,917:INFO:Importing untrained model
2024-07-30 23:28:24,919:INFO:Logistic Regression Imported successfully
2024-07-30 23:28:24,922:INFO:Starting cross validation
2024-07-30 23:28:24,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:25,006:INFO:Calculating mean and std
2024-07-30 23:28:25,006:INFO:Creating metrics dataframe
2024-07-30 23:28:25,009:INFO:Finalizing model
2024-07-30 23:28:25,030:INFO:Uploading results into container
2024-07-30 23:28:25,031:INFO:Uploading model into container now
2024-07-30 23:28:25,035:INFO:_master_model_container: 17
2024-07-30 23:28:25,035:INFO:_display_container: 3
2024-07-30 23:28:25,035:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-30 23:28:25,035:INFO:create_model() successfully completed......................................
2024-07-30 23:28:25,096:INFO:Initializing tune_model()
2024-07-30 23:28:25,096:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>)
2024-07-30 23:28:25,096:INFO:Checking exceptions
2024-07-30 23:28:25,103:INFO:Copying training dataset
2024-07-30 23:28:25,104:INFO:Checking base model
2024-07-30 23:28:25,105:INFO:Base model : Logistic Regression
2024-07-30 23:28:25,106:INFO:Declaring metric variables
2024-07-30 23:28:25,108:INFO:Defining Hyperparameters
2024-07-30 23:28:25,169:INFO:Tuning with n_jobs=-1
2024-07-30 23:28:25,169:INFO:Initializing RandomizedSearchCV
2024-07-30 23:28:25,499:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 2.373}
2024-07-30 23:28:25,499:INFO:Hyperparameter search completed
2024-07-30 23:28:25,499:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:25,500:INFO:Initializing create_model()
2024-07-30 23:28:25,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x3569c5b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 2.373})
2024-07-30 23:28:25,500:INFO:Checking exceptions
2024-07-30 23:28:25,500:INFO:Importing libraries
2024-07-30 23:28:25,500:INFO:Copying training dataset
2024-07-30 23:28:25,502:INFO:Defining folds
2024-07-30 23:28:25,502:INFO:Declaring metric variables
2024-07-30 23:28:25,504:INFO:Importing untrained model
2024-07-30 23:28:25,504:INFO:Declaring custom model
2024-07-30 23:28:25,506:INFO:Logistic Regression Imported successfully
2024-07-30 23:28:25,509:INFO:Starting cross validation
2024-07-30 23:28:25,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:25,564:INFO:Calculating mean and std
2024-07-30 23:28:25,565:INFO:Creating metrics dataframe
2024-07-30 23:28:25,567:INFO:Finalizing model
2024-07-30 23:28:25,589:INFO:Uploading results into container
2024-07-30 23:28:25,589:INFO:Uploading model into container now
2024-07-30 23:28:25,589:INFO:_master_model_container: 18
2024-07-30 23:28:25,590:INFO:_display_container: 4
2024-07-30 23:28:25,590:INFO:LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-30 23:28:25,590:INFO:create_model() successfully completed......................................
2024-07-30 23:28:25,653:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:25,653:INFO:choose_better activated
2024-07-30 23:28:25,655:INFO:SubProcess create_model() called ==================================
2024-07-30 23:28:25,655:INFO:Initializing create_model()
2024-07-30 23:28:25,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:28:25,655:INFO:Checking exceptions
2024-07-30 23:28:25,656:INFO:Importing libraries
2024-07-30 23:28:25,656:INFO:Copying training dataset
2024-07-30 23:28:25,658:INFO:Defining folds
2024-07-30 23:28:25,659:INFO:Declaring metric variables
2024-07-30 23:28:25,659:INFO:Importing untrained model
2024-07-30 23:28:25,659:INFO:Declaring custom model
2024-07-30 23:28:25,659:INFO:Logistic Regression Imported successfully
2024-07-30 23:28:25,659:INFO:Starting cross validation
2024-07-30 23:28:25,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-30 23:28:25,727:INFO:Calculating mean and std
2024-07-30 23:28:25,727:INFO:Creating metrics dataframe
2024-07-30 23:28:25,728:INFO:Finalizing model
2024-07-30 23:28:25,747:INFO:Uploading results into container
2024-07-30 23:28:25,747:INFO:Uploading model into container now
2024-07-30 23:28:25,747:INFO:_master_model_container: 19
2024-07-30 23:28:25,747:INFO:_display_container: 5
2024-07-30 23:28:25,748:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-30 23:28:25,748:INFO:create_model() successfully completed......................................
2024-07-30 23:28:25,799:INFO:SubProcess create_model() end ==================================
2024-07-30 23:28:25,800:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.7839
2024-07-30 23:28:25,800:INFO:LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.7964
2024-07-30 23:28:25,800:INFO:LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-07-30 23:28:25,800:INFO:choose_better completed
2024-07-30 23:28:25,804:INFO:_master_model_container: 19
2024-07-30 23:28:25,804:INFO:_display_container: 4
2024-07-30 23:28:25,804:INFO:LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-30 23:28:25,804:INFO:tune_model() successfully completed......................................
2024-07-30 23:43:47,062:INFO:Initializing plot_model()
2024-07-30 23:43:47,062:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, system=True)
2024-07-30 23:43:47,062:INFO:Checking exceptions
2024-07-30 23:43:47,066:INFO:Preloading libraries
2024-07-30 23:43:47,066:INFO:Copying training dataset
2024-07-30 23:43:47,066:INFO:Plot type: feature
2024-07-30 23:43:47,210:INFO:Visual Rendered Successfully
2024-07-30 23:43:47,287:INFO:plot_model() successfully completed......................................
2024-07-30 23:44:04,491:INFO:Initializing evaluate_model()
2024-07-30 23:44:04,491:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-30 23:44:04,501:INFO:Initializing plot_model()
2024-07-30 23:44:04,501:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, system=True)
2024-07-30 23:44:04,501:INFO:Checking exceptions
2024-07-30 23:44:04,503:INFO:Preloading libraries
2024-07-30 23:44:04,503:INFO:Copying training dataset
2024-07-30 23:44:04,503:INFO:Plot type: pipeline
2024-07-30 23:44:04,588:INFO:Visual Rendered Successfully
2024-07-30 23:44:04,646:INFO:plot_model() successfully completed......................................
2024-07-30 23:44:07,658:INFO:Initializing plot_model()
2024-07-30 23:44:07,658:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, system=True)
2024-07-30 23:44:07,658:INFO:Checking exceptions
2024-07-30 23:44:07,661:INFO:Preloading libraries
2024-07-30 23:44:07,661:INFO:Copying training dataset
2024-07-30 23:44:07,662:INFO:Plot type: parameter
2024-07-30 23:44:07,664:INFO:Visual Rendered Successfully
2024-07-30 23:44:07,738:INFO:plot_model() successfully completed......................................
2024-07-30 23:44:09,967:INFO:Initializing plot_model()
2024-07-30 23:44:09,968:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, system=True)
2024-07-30 23:44:09,968:INFO:Checking exceptions
2024-07-30 23:44:09,971:INFO:Preloading libraries
2024-07-30 23:44:09,971:INFO:Copying training dataset
2024-07-30 23:44:09,971:INFO:Plot type: pipeline
2024-07-30 23:44:10,048:INFO:Visual Rendered Successfully
2024-07-30 23:44:10,115:INFO:plot_model() successfully completed......................................
2024-07-30 23:44:16,304:INFO:Initializing predict_model()
2024-07-30 23:44:16,304:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x352ebca60>)
2024-07-30 23:44:16,305:INFO:Checking exceptions
2024-07-30 23:44:16,305:INFO:Preloading libraries
2024-07-30 23:44:23,450:INFO:Initializing finalize_model()
2024-07-30 23:44:23,451:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-30 23:44:23,451:INFO:Finalizing LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-30 23:44:23,455:INFO:Initializing create_model()
2024-07-30 23:44:23,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-30 23:44:23,455:INFO:Checking exceptions
2024-07-30 23:44:23,456:INFO:Importing libraries
2024-07-30 23:44:23,456:INFO:Copying training dataset
2024-07-30 23:44:23,457:INFO:Defining folds
2024-07-30 23:44:23,457:INFO:Declaring metric variables
2024-07-30 23:44:23,457:INFO:Importing untrained model
2024-07-30 23:44:23,457:INFO:Declaring custom model
2024-07-30 23:44:23,457:INFO:Logistic Regression Imported successfully
2024-07-30 23:44:23,458:INFO:Cross validation set to False
2024-07-30 23:44:23,458:INFO:Fitting Model
2024-07-30 23:44:23,492:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-30 23:44:23,492:INFO:create_model() successfully completed......................................
2024-07-30 23:44:23,561:INFO:_master_model_container: 19
2024-07-30 23:44:23,562:INFO:_display_container: 5
2024-07-30 23:44:23,568:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-30 23:44:23,568:INFO:finalize_model() successfully completed......................................
2024-07-30 23:44:47,539:INFO:Initializing predict_model()
2024-07-30 23:44:47,539:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x352ebc280>)
2024-07-30 23:44:47,540:INFO:Checking exceptions
2024-07-30 23:44:47,540:INFO:Preloading libraries
2024-07-30 23:44:47,542:INFO:Set up data.
2024-07-30 23:44:47,549:INFO:Set up index.
2024-07-30 23:46:01,376:INFO:Initializing interpret_model()
2024-07-30 23:46:01,376:INFO:interpret_model(estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>)
2024-07-30 23:46:01,376:INFO:Checking exceptions
2024-07-30 23:46:01,376:INFO:Soft dependency imported: shap: 0.44.1
2024-07-30 23:46:29,076:INFO:Initializing interpret_model()
2024-07-30 23:46:29,076:INFO:interpret_model(estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>)
2024-07-30 23:46:29,076:INFO:Checking exceptions
2024-07-30 23:46:29,077:INFO:Soft dependency imported: shap: 0.44.1
2024-07-30 23:49:39,049:INFO:Initializing plot_model()
2024-07-30 23:49:39,049:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=2.373, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2110, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, system=True)
2024-07-30 23:49:39,050:INFO:Checking exceptions
2024-07-30 23:49:39,052:INFO:Preloading libraries
2024-07-30 23:49:39,052:INFO:Copying training dataset
2024-07-30 23:49:39,052:INFO:Plot type: auc
2024-07-30 23:49:39,144:INFO:Fitting Model
2024-07-30 23:49:39,144:WARNING:X does not have valid feature names, but LogisticRegression was fitted with feature names

2024-07-30 23:49:39,144:INFO:Scoring test/hold-out set
2024-07-30 23:49:39,230:INFO:Visual Rendered Successfully
2024-07-30 23:49:39,300:INFO:plot_model() successfully completed......................................
2024-07-30 23:54:52,781:INFO:Initializing predict_model()
2024-07-30 23:54:52,781:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x354697670>)
2024-07-30 23:54:52,781:INFO:Checking exceptions
2024-07-30 23:54:52,781:INFO:Preloading libraries
2024-07-30 23:54:52,783:INFO:Set up data.
2024-07-30 23:54:52,788:INFO:Set up index.
2024-07-30 23:56:20,499:INFO:Initializing predict_model()
2024-07-30 23:56:20,499:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x35b12cee0>)
2024-07-30 23:56:20,499:INFO:Checking exceptions
2024-07-30 23:56:20,499:INFO:Preloading libraries
2024-07-30 23:56:27,013:INFO:Initializing plot_model()
2024-07-30 23:56:27,013:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, system=True)
2024-07-30 23:56:27,013:INFO:Checking exceptions
2024-07-30 23:56:27,016:INFO:Preloading libraries
2024-07-30 23:56:27,017:INFO:Copying training dataset
2024-07-30 23:56:27,017:INFO:Plot type: feature
2024-07-30 23:56:27,132:INFO:Visual Rendered Successfully
2024-07-30 23:56:27,202:INFO:plot_model() successfully completed......................................
2024-07-30 23:56:33,944:INFO:Initializing evaluate_model()
2024-07-30 23:56:33,944:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-30 23:56:33,963:INFO:Initializing plot_model()
2024-07-30 23:56:33,963:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, system=True)
2024-07-30 23:56:33,963:INFO:Checking exceptions
2024-07-30 23:56:33,965:INFO:Preloading libraries
2024-07-30 23:56:33,966:INFO:Copying training dataset
2024-07-30 23:56:33,966:INFO:Plot type: pipeline
2024-07-30 23:56:34,038:INFO:Visual Rendered Successfully
2024-07-30 23:56:34,111:INFO:plot_model() successfully completed......................................
2024-07-30 23:56:35,927:INFO:Initializing plot_model()
2024-07-30 23:56:35,927:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, system=True)
2024-07-30 23:56:35,927:INFO:Checking exceptions
2024-07-30 23:56:35,929:INFO:Preloading libraries
2024-07-30 23:56:35,930:INFO:Copying training dataset
2024-07-30 23:56:35,930:INFO:Plot type: auc
2024-07-30 23:56:36,030:INFO:Fitting Model
2024-07-30 23:56:36,031:WARNING:X does not have valid feature names, but LogisticRegression was fitted with feature names

2024-07-30 23:56:36,031:INFO:Scoring test/hold-out set
2024-07-30 23:56:36,116:INFO:Visual Rendered Successfully
2024-07-30 23:56:36,189:INFO:plot_model() successfully completed......................................
2024-07-30 23:56:40,236:INFO:Initializing predict_model()
2024-07-30 23:56:40,236:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1067fea30>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=2.373, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=2110,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x35a4e0940>)
2024-07-30 23:56:40,236:INFO:Checking exceptions
2024-07-30 23:56:40,236:INFO:Preloading libraries
2024-07-30 23:56:40,238:INFO:Set up data.
2024-07-30 23:56:40,243:INFO:Set up index.
2024-07-31 00:41:38,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-31 00:41:38,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-31 00:41:38,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-31 00:41:38,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-31 00:41:38,519:INFO:PyCaret ClassificationExperiment
2024-07-31 00:41:38,519:INFO:Logging name: clf-default-name
2024-07-31 00:41:38,519:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-31 00:41:38,519:INFO:version 3.3.2
2024-07-31 00:41:38,519:INFO:Initializing setup()
2024-07-31 00:41:38,519:INFO:self.USI: 4fed
2024-07-31 00:41:38,519:INFO:self._variable_keys: {'idx', 'seed', 'log_plots_param', 'target_param', 'is_multiclass', 'fold_groups_param', 'X_test', 'y_train', 'memory', 'y_test', 'y', 'X', '_ml_usecase', 'exp_id', 'logging_param', 'USI', '_available_plots', 'fix_imbalance', 'X_train', 'exp_name_log', 'gpu_n_jobs_param', 'pipeline', 'fold_shuffle_param', 'html_param', 'data', 'n_jobs_param', 'gpu_param', 'fold_generator'}
2024-07-31 00:41:38,519:INFO:Checking environment
2024-07-31 00:41:38,519:INFO:python_version: 3.9.6
2024-07-31 00:41:38,519:INFO:python_build: ('default', 'Feb  3 2024 15:58:27')
2024-07-31 00:41:38,519:INFO:machine: arm64
2024-07-31 00:41:38,519:INFO:platform: macOS-14.4-arm64-arm-64bit
2024-07-31 00:41:38,519:INFO:Memory: svmem(total=38654705664, available=19069583360, percent=50.7, used=18647826432, free=2926084096, active=15767732224, inactive=13202915328, wired=2880094208)
2024-07-31 00:41:38,519:INFO:Physical Core: 14
2024-07-31 00:41:38,519:INFO:Logical Core: 14
2024-07-31 00:41:38,519:INFO:Checking libraries
2024-07-31 00:41:38,519:INFO:System:
2024-07-31 00:41:38,519:INFO:    python: 3.9.6 (default, Feb  3 2024, 15:58:27)  [Clang 15.0.0 (clang-1500.3.9.4)]
2024-07-31 00:41:38,519:INFO:executable: /Library/Developer/CommandLineTools/usr/bin/python3
2024-07-31 00:41:38,519:INFO:   machine: macOS-14.4-arm64-arm-64bit
2024-07-31 00:41:38,519:INFO:PyCaret required dependencies:
2024-07-31 00:41:38,786:INFO:                 pip: 21.2.4
2024-07-31 00:41:38,786:INFO:          setuptools: 58.0.4
2024-07-31 00:41:38,786:INFO:             pycaret: 3.3.2
2024-07-31 00:41:38,786:INFO:             IPython: 8.18.1
2024-07-31 00:41:38,786:INFO:          ipywidgets: 7.8.3
2024-07-31 00:41:38,786:INFO:                tqdm: 4.66.4
2024-07-31 00:41:38,786:INFO:               numpy: 1.23.5
2024-07-31 00:41:38,786:INFO:              pandas: 2.0.3
2024-07-31 00:41:38,786:INFO:              jinja2: 3.1.4
2024-07-31 00:41:38,786:INFO:               scipy: 1.10.1
2024-07-31 00:41:38,786:INFO:              joblib: 1.3.2
2024-07-31 00:41:38,786:INFO:             sklearn: 1.4.2
2024-07-31 00:41:38,786:INFO:                pyod: 2.0.1
2024-07-31 00:41:38,786:INFO:            imblearn: 0.12.3
2024-07-31 00:41:38,786:INFO:   category_encoders: 2.6.3
2024-07-31 00:41:38,786:INFO:            lightgbm: 4.4.0
2024-07-31 00:41:38,786:INFO:               numba: 0.58.1
2024-07-31 00:41:38,786:INFO:            requests: 2.32.3
2024-07-31 00:41:38,786:INFO:          matplotlib: 3.7.3
2024-07-31 00:41:38,786:INFO:          scikitplot: 0.3.7
2024-07-31 00:41:38,786:INFO:         yellowbrick: 1.5
2024-07-31 00:41:38,786:INFO:              plotly: 5.23.0
2024-07-31 00:41:38,786:INFO:    plotly-resampler: Not installed
2024-07-31 00:41:38,786:INFO:             kaleido: 0.2.1
2024-07-31 00:41:38,786:INFO:           schemdraw: 0.15
2024-07-31 00:41:38,787:INFO:         statsmodels: 0.14.2
2024-07-31 00:41:38,787:INFO:              sktime: 0.26.0
2024-07-31 00:41:38,787:INFO:               tbats: 1.1.3
2024-07-31 00:41:38,787:INFO:            pmdarima: 2.0.4
2024-07-31 00:41:38,787:INFO:              psutil: 6.0.0
2024-07-31 00:41:38,787:INFO:          markupsafe: 2.1.5
2024-07-31 00:41:38,787:INFO:             pickle5: Not installed
2024-07-31 00:41:38,787:INFO:         cloudpickle: 2.2.1
2024-07-31 00:41:38,787:INFO:         deprecation: 2.1.0
2024-07-31 00:41:38,787:INFO:              xxhash: 3.4.1
2024-07-31 00:41:38,787:INFO:           wurlitzer: 3.1.1
2024-07-31 00:41:38,787:INFO:PyCaret optional dependencies:
2024-07-31 00:41:39,086:INFO:                shap: 0.44.1
2024-07-31 00:41:39,086:INFO:           interpret: 0.6.2
2024-07-31 00:41:39,086:INFO:                umap: 0.5.6
2024-07-31 00:41:39,086:INFO:     ydata_profiling: 4.6.0
2024-07-31 00:41:39,086:INFO:  explainerdashboard: 0.4.7
2024-07-31 00:41:39,086:INFO:             autoviz: 0.1.902
2024-07-31 00:41:39,086:INFO:           fairlearn: 0.7.0
2024-07-31 00:41:39,086:INFO:          deepchecks: 0.18.1
2024-07-31 00:41:39,086:INFO:             xgboost: 1.6.2
2024-07-31 00:41:39,086:INFO:            catboost: 1.1.1
2024-07-31 00:41:39,086:INFO:              kmodes: 0.12.2
2024-07-31 00:41:39,086:INFO:             mlxtend: 0.23.1
2024-07-31 00:41:39,086:INFO:       statsforecast: 1.5.0
2024-07-31 00:41:39,086:INFO:        tune_sklearn: 0.1.5
2024-07-31 00:41:39,086:INFO:                 ray: 2.33.0
2024-07-31 00:41:39,086:INFO:            hyperopt: 0.2.7
2024-07-31 00:41:39,086:INFO:              optuna: 3.6.1
2024-07-31 00:41:39,086:INFO:               skopt: 0.10.2
2024-07-31 00:41:39,086:INFO:              mlflow: 2.15.0
2024-07-31 00:41:39,086:INFO:              gradio: 3.50.2
2024-07-31 00:41:39,086:INFO:             fastapi: 0.111.1
2024-07-31 00:41:39,086:INFO:             uvicorn: 0.30.3
2024-07-31 00:41:39,086:INFO:              m2cgen: 0.10.0
2024-07-31 00:41:39,086:INFO:           evidently: 0.4.32
2024-07-31 00:41:39,086:INFO:               fugue: 0.8.7
2024-07-31 00:41:39,086:INFO:           streamlit: Not installed
2024-07-31 00:41:39,086:INFO:             prophet: Not installed
2024-07-31 00:41:39,086:INFO:None
2024-07-31 00:41:39,086:INFO:Set up data.
2024-07-31 00:41:39,090:INFO:Set up folding strategy.
2024-07-31 00:41:39,090:INFO:Set up train/test split.
2024-07-31 00:41:39,093:INFO:Set up index.
2024-07-31 00:41:39,093:INFO:Assigning column types.
2024-07-31 00:41:39,095:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-31 00:41:39,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-31 00:41:39,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-31 00:41:39,124:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-31 00:41:39,133:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-31 00:41:39,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-31 00:41:39,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-31 00:41:39,168:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-31 00:41:39,169:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-31 00:41:39,170:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-31 00:41:39,186:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-31 00:41:39,196:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-31 00:41:39,197:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-31 00:41:39,213:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-31 00:41:39,223:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-31 00:41:39,224:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-31 00:41:39,224:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-31 00:41:39,250:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-31 00:41:39,251:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-31 00:41:39,278:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-31 00:41:39,279:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-31 00:41:39,280:INFO:Preparing preprocessing pipeline...
2024-07-31 00:41:39,280:INFO:Set up simple imputation.
2024-07-31 00:41:39,281:INFO:Set up encoding of ordinal features.
2024-07-31 00:41:39,282:INFO:Set up encoding of categorical features.
2024-07-31 00:41:39,282:INFO:Set up column name cleaning.
2024-07-31 00:41:39,314:INFO:Finished creating preprocessing pipeline.
2024-07-31 00:41:39,320:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/4f/9jwcfl7s6sz9pnhpf52ybf500000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=Simple...
                 TransformerWrapper(exclude=None, include=['ethnicity'],
                                    transformer=OneHotEncoder(cols=['ethnicity'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-07-31 00:41:39,320:INFO:Creating final display dataframe.
2024-07-31 00:41:39,408:INFO:Setup _display_container:                     Description             Value
0                    Session id              1999
1                        Target         Class/ASD
2                   Target type            Binary
3           Original data shape         (114, 29)
4        Transformed data shape         (114, 29)
5   Transformed train set shape          (79, 29)
6    Transformed test set shape          (35, 29)
7              Numeric features                26
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              4fed
2024-07-31 00:41:39,435:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-31 00:41:39,436:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-31 00:41:39,464:INFO:Soft dependency imported: xgboost: 1.6.2
2024-07-31 00:41:39,465:INFO:Soft dependency imported: catboost: 1.1.1
2024-07-31 00:41:39,465:INFO:setup() successfully completed in 0.95s...............
2024-07-31 00:41:39,470:INFO:Initializing compare_models()
2024-07-31 00:41:39,470:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-07-31 00:41:39,470:INFO:Checking exceptions
2024-07-31 00:41:39,472:INFO:Preparing display monitor
2024-07-31 00:41:39,496:INFO:Initializing Logistic Regression
2024-07-31 00:41:39,496:INFO:Total runtime is 2.5987625122070313e-06 minutes
2024-07-31 00:41:39,497:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:39,497:INFO:Initializing create_model()
2024-07-31 00:41:39,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:39,497:INFO:Checking exceptions
2024-07-31 00:41:39,497:INFO:Importing libraries
2024-07-31 00:41:39,498:INFO:Copying training dataset
2024-07-31 00:41:39,501:INFO:Defining folds
2024-07-31 00:41:39,501:INFO:Declaring metric variables
2024-07-31 00:41:39,502:INFO:Importing untrained model
2024-07-31 00:41:39,504:INFO:Logistic Regression Imported successfully
2024-07-31 00:41:39,507:INFO:Starting cross validation
2024-07-31 00:41:39,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:41,586:INFO:Calculating mean and std
2024-07-31 00:41:41,588:INFO:Creating metrics dataframe
2024-07-31 00:41:41,590:INFO:Uploading results into container
2024-07-31 00:41:41,590:INFO:Uploading model into container now
2024-07-31 00:41:41,591:INFO:_master_model_container: 1
2024-07-31 00:41:41,591:INFO:_display_container: 2
2024-07-31 00:41:41,592:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-31 00:41:41,592:INFO:create_model() successfully completed......................................
2024-07-31 00:41:41,664:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:41,664:INFO:Creating metrics dataframe
2024-07-31 00:41:41,667:INFO:Initializing K Neighbors Classifier
2024-07-31 00:41:41,667:INFO:Total runtime is 0.03618728717168172 minutes
2024-07-31 00:41:41,668:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:41,668:INFO:Initializing create_model()
2024-07-31 00:41:41,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:41,669:INFO:Checking exceptions
2024-07-31 00:41:41,669:INFO:Importing libraries
2024-07-31 00:41:41,669:INFO:Copying training dataset
2024-07-31 00:41:41,671:INFO:Defining folds
2024-07-31 00:41:41,671:INFO:Declaring metric variables
2024-07-31 00:41:41,673:INFO:Importing untrained model
2024-07-31 00:41:41,674:INFO:K Neighbors Classifier Imported successfully
2024-07-31 00:41:41,677:INFO:Starting cross validation
2024-07-31 00:41:41,678:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:42,780:INFO:Calculating mean and std
2024-07-31 00:41:42,781:INFO:Creating metrics dataframe
2024-07-31 00:41:42,782:INFO:Uploading results into container
2024-07-31 00:41:42,782:INFO:Uploading model into container now
2024-07-31 00:41:42,782:INFO:_master_model_container: 2
2024-07-31 00:41:42,783:INFO:_display_container: 2
2024-07-31 00:41:42,783:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-31 00:41:42,783:INFO:create_model() successfully completed......................................
2024-07-31 00:41:42,843:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:42,843:INFO:Creating metrics dataframe
2024-07-31 00:41:42,846:INFO:Initializing Naive Bayes
2024-07-31 00:41:42,846:INFO:Total runtime is 0.0558465043703715 minutes
2024-07-31 00:41:42,848:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:42,848:INFO:Initializing create_model()
2024-07-31 00:41:42,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:42,848:INFO:Checking exceptions
2024-07-31 00:41:42,848:INFO:Importing libraries
2024-07-31 00:41:42,848:INFO:Copying training dataset
2024-07-31 00:41:42,851:INFO:Defining folds
2024-07-31 00:41:42,851:INFO:Declaring metric variables
2024-07-31 00:41:42,852:INFO:Importing untrained model
2024-07-31 00:41:42,854:INFO:Naive Bayes Imported successfully
2024-07-31 00:41:42,856:INFO:Starting cross validation
2024-07-31 00:41:42,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:43,870:INFO:Calculating mean and std
2024-07-31 00:41:43,871:INFO:Creating metrics dataframe
2024-07-31 00:41:43,872:INFO:Uploading results into container
2024-07-31 00:41:43,872:INFO:Uploading model into container now
2024-07-31 00:41:43,872:INFO:_master_model_container: 3
2024-07-31 00:41:43,873:INFO:_display_container: 2
2024-07-31 00:41:43,873:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-31 00:41:43,873:INFO:create_model() successfully completed......................................
2024-07-31 00:41:43,927:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:43,927:INFO:Creating metrics dataframe
2024-07-31 00:41:43,930:INFO:Initializing Decision Tree Classifier
2024-07-31 00:41:43,930:INFO:Total runtime is 0.07391565243403117 minutes
2024-07-31 00:41:43,932:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:43,932:INFO:Initializing create_model()
2024-07-31 00:41:43,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:43,932:INFO:Checking exceptions
2024-07-31 00:41:43,932:INFO:Importing libraries
2024-07-31 00:41:43,933:INFO:Copying training dataset
2024-07-31 00:41:43,935:INFO:Defining folds
2024-07-31 00:41:43,935:INFO:Declaring metric variables
2024-07-31 00:41:43,936:INFO:Importing untrained model
2024-07-31 00:41:43,937:INFO:Decision Tree Classifier Imported successfully
2024-07-31 00:41:43,940:INFO:Starting cross validation
2024-07-31 00:41:43,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:44,022:INFO:Calculating mean and std
2024-07-31 00:41:44,022:INFO:Creating metrics dataframe
2024-07-31 00:41:44,023:INFO:Uploading results into container
2024-07-31 00:41:44,023:INFO:Uploading model into container now
2024-07-31 00:41:44,024:INFO:_master_model_container: 4
2024-07-31 00:41:44,024:INFO:_display_container: 2
2024-07-31 00:41:44,024:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1999, splitter='best')
2024-07-31 00:41:44,024:INFO:create_model() successfully completed......................................
2024-07-31 00:41:44,078:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:44,079:INFO:Creating metrics dataframe
2024-07-31 00:41:44,082:INFO:Initializing SVM - Linear Kernel
2024-07-31 00:41:44,082:INFO:Total runtime is 0.07644104957580566 minutes
2024-07-31 00:41:44,084:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:44,084:INFO:Initializing create_model()
2024-07-31 00:41:44,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:44,084:INFO:Checking exceptions
2024-07-31 00:41:44,084:INFO:Importing libraries
2024-07-31 00:41:44,084:INFO:Copying training dataset
2024-07-31 00:41:44,087:INFO:Defining folds
2024-07-31 00:41:44,087:INFO:Declaring metric variables
2024-07-31 00:41:44,088:INFO:Importing untrained model
2024-07-31 00:41:44,089:INFO:SVM - Linear Kernel Imported successfully
2024-07-31 00:41:44,092:INFO:Starting cross validation
2024-07-31 00:41:44,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:44,136:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,158:INFO:Calculating mean and std
2024-07-31 00:41:44,159:INFO:Creating metrics dataframe
2024-07-31 00:41:44,160:INFO:Uploading results into container
2024-07-31 00:41:44,160:INFO:Uploading model into container now
2024-07-31 00:41:44,160:INFO:_master_model_container: 5
2024-07-31 00:41:44,160:INFO:_display_container: 2
2024-07-31 00:41:44,160:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1999, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-31 00:41:44,160:INFO:create_model() successfully completed......................................
2024-07-31 00:41:44,214:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:44,214:INFO:Creating metrics dataframe
2024-07-31 00:41:44,218:INFO:Initializing Ridge Classifier
2024-07-31 00:41:44,218:INFO:Total runtime is 0.07871067126592 minutes
2024-07-31 00:41:44,220:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:44,220:INFO:Initializing create_model()
2024-07-31 00:41:44,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:44,220:INFO:Checking exceptions
2024-07-31 00:41:44,220:INFO:Importing libraries
2024-07-31 00:41:44,220:INFO:Copying training dataset
2024-07-31 00:41:44,223:INFO:Defining folds
2024-07-31 00:41:44,223:INFO:Declaring metric variables
2024-07-31 00:41:44,224:INFO:Importing untrained model
2024-07-31 00:41:44,225:INFO:Ridge Classifier Imported successfully
2024-07-31 00:41:44,228:INFO:Starting cross validation
2024-07-31 00:41:44,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:44,281:INFO:Calculating mean and std
2024-07-31 00:41:44,282:INFO:Creating metrics dataframe
2024-07-31 00:41:44,283:INFO:Uploading results into container
2024-07-31 00:41:44,283:INFO:Uploading model into container now
2024-07-31 00:41:44,283:INFO:_master_model_container: 6
2024-07-31 00:41:44,283:INFO:_display_container: 2
2024-07-31 00:41:44,284:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1999, solver='auto',
                tol=0.0001)
2024-07-31 00:41:44,284:INFO:create_model() successfully completed......................................
2024-07-31 00:41:44,337:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:44,337:INFO:Creating metrics dataframe
2024-07-31 00:41:44,341:INFO:Initializing Random Forest Classifier
2024-07-31 00:41:44,341:INFO:Total runtime is 0.08075530529022217 minutes
2024-07-31 00:41:44,342:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:44,342:INFO:Initializing create_model()
2024-07-31 00:41:44,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:44,343:INFO:Checking exceptions
2024-07-31 00:41:44,343:INFO:Importing libraries
2024-07-31 00:41:44,343:INFO:Copying training dataset
2024-07-31 00:41:44,346:INFO:Defining folds
2024-07-31 00:41:44,346:INFO:Declaring metric variables
2024-07-31 00:41:44,347:INFO:Importing untrained model
2024-07-31 00:41:44,348:INFO:Random Forest Classifier Imported successfully
2024-07-31 00:41:44,351:INFO:Starting cross validation
2024-07-31 00:41:44,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:44,551:INFO:Calculating mean and std
2024-07-31 00:41:44,552:INFO:Creating metrics dataframe
2024-07-31 00:41:44,552:INFO:Uploading results into container
2024-07-31 00:41:44,553:INFO:Uploading model into container now
2024-07-31 00:41:44,553:INFO:_master_model_container: 7
2024-07-31 00:41:44,553:INFO:_display_container: 2
2024-07-31 00:41:44,553:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1999, verbose=0,
                       warm_start=False)
2024-07-31 00:41:44,554:INFO:create_model() successfully completed......................................
2024-07-31 00:41:44,612:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:44,612:INFO:Creating metrics dataframe
2024-07-31 00:41:44,616:INFO:Initializing Quadratic Discriminant Analysis
2024-07-31 00:41:44,616:INFO:Total runtime is 0.08533995151519776 minutes
2024-07-31 00:41:44,617:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:44,618:INFO:Initializing create_model()
2024-07-31 00:41:44,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:44,618:INFO:Checking exceptions
2024-07-31 00:41:44,618:INFO:Importing libraries
2024-07-31 00:41:44,618:INFO:Copying training dataset
2024-07-31 00:41:44,621:INFO:Defining folds
2024-07-31 00:41:44,621:INFO:Declaring metric variables
2024-07-31 00:41:44,622:INFO:Importing untrained model
2024-07-31 00:41:44,623:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-31 00:41:44,626:INFO:Starting cross validation
2024-07-31 00:41:44,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:44,653:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,654:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,655:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,659:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,661:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,662:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,662:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,662:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,663:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,663:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,663:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,663:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,663:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,663:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,663:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,664:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,664:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,664:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,664:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,665:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,665:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,665:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,665:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,665:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,665:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,668:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,668:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,669:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,669:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,669:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,669:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,669:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,670:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,670:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,670:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,670:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,670:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,670:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,671:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,671:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,672:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,672:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,672:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,672:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,673:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,673:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,673:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,673:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,673:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,674:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,674:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,674:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,674:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,675:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,675:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,675:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,675:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,676:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-31 00:41:44,678:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,678:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,680:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,680:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,680:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,680:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,681:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,681:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,681:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,681:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,681:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,681:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,681:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,681:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,682:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,682:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,682:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,683:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,684:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,685:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,685:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,685:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,686:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,686:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,686:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-31 00:41:44,686:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-31 00:41:44,689:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,689:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,692:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,692:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,693:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-31 00:41:44,696:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-31 00:41:44,706:INFO:Calculating mean and std
2024-07-31 00:41:44,707:INFO:Creating metrics dataframe
2024-07-31 00:41:44,708:INFO:Uploading results into container
2024-07-31 00:41:44,708:INFO:Uploading model into container now
2024-07-31 00:41:44,709:INFO:_master_model_container: 8
2024-07-31 00:41:44,709:INFO:_display_container: 2
2024-07-31 00:41:44,709:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-31 00:41:44,709:INFO:create_model() successfully completed......................................
2024-07-31 00:41:44,764:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:44,764:INFO:Creating metrics dataframe
2024-07-31 00:41:44,767:INFO:Initializing Ada Boost Classifier
2024-07-31 00:41:44,768:INFO:Total runtime is 0.08786850372950236 minutes
2024-07-31 00:41:44,769:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:44,769:INFO:Initializing create_model()
2024-07-31 00:41:44,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:44,769:INFO:Checking exceptions
2024-07-31 00:41:44,769:INFO:Importing libraries
2024-07-31 00:41:44,769:INFO:Copying training dataset
2024-07-31 00:41:44,772:INFO:Defining folds
2024-07-31 00:41:44,772:INFO:Declaring metric variables
2024-07-31 00:41:44,773:INFO:Importing untrained model
2024-07-31 00:41:44,774:INFO:Ada Boost Classifier Imported successfully
2024-07-31 00:41:44,777:INFO:Starting cross validation
2024-07-31 00:41:44,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:44,804:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,806:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,807:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,808:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,808:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,811:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,812:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,817:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,821:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,824:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-31 00:41:44,868:INFO:Calculating mean and std
2024-07-31 00:41:44,869:INFO:Creating metrics dataframe
2024-07-31 00:41:44,870:INFO:Uploading results into container
2024-07-31 00:41:44,870:INFO:Uploading model into container now
2024-07-31 00:41:44,870:INFO:_master_model_container: 9
2024-07-31 00:41:44,870:INFO:_display_container: 2
2024-07-31 00:41:44,870:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1999)
2024-07-31 00:41:44,870:INFO:create_model() successfully completed......................................
2024-07-31 00:41:44,928:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:44,928:INFO:Creating metrics dataframe
2024-07-31 00:41:44,933:INFO:Initializing Gradient Boosting Classifier
2024-07-31 00:41:44,933:INFO:Total runtime is 0.09061930179595948 minutes
2024-07-31 00:41:44,934:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:44,934:INFO:Initializing create_model()
2024-07-31 00:41:44,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:44,934:INFO:Checking exceptions
2024-07-31 00:41:44,934:INFO:Importing libraries
2024-07-31 00:41:44,934:INFO:Copying training dataset
2024-07-31 00:41:44,937:INFO:Defining folds
2024-07-31 00:41:44,937:INFO:Declaring metric variables
2024-07-31 00:41:44,938:INFO:Importing untrained model
2024-07-31 00:41:44,940:INFO:Gradient Boosting Classifier Imported successfully
2024-07-31 00:41:44,942:INFO:Starting cross validation
2024-07-31 00:41:44,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:45,035:INFO:Calculating mean and std
2024-07-31 00:41:45,036:INFO:Creating metrics dataframe
2024-07-31 00:41:45,037:INFO:Uploading results into container
2024-07-31 00:41:45,037:INFO:Uploading model into container now
2024-07-31 00:41:45,037:INFO:_master_model_container: 10
2024-07-31 00:41:45,037:INFO:_display_container: 2
2024-07-31 00:41:45,037:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1999, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-31 00:41:45,038:INFO:create_model() successfully completed......................................
2024-07-31 00:41:45,093:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:45,093:INFO:Creating metrics dataframe
2024-07-31 00:41:45,097:INFO:Initializing Linear Discriminant Analysis
2024-07-31 00:41:45,097:INFO:Total runtime is 0.09335941871007285 minutes
2024-07-31 00:41:45,098:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:45,099:INFO:Initializing create_model()
2024-07-31 00:41:45,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:45,099:INFO:Checking exceptions
2024-07-31 00:41:45,099:INFO:Importing libraries
2024-07-31 00:41:45,099:INFO:Copying training dataset
2024-07-31 00:41:45,102:INFO:Defining folds
2024-07-31 00:41:45,102:INFO:Declaring metric variables
2024-07-31 00:41:45,103:INFO:Importing untrained model
2024-07-31 00:41:45,104:INFO:Linear Discriminant Analysis Imported successfully
2024-07-31 00:41:45,107:INFO:Starting cross validation
2024-07-31 00:41:45,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:45,164:INFO:Calculating mean and std
2024-07-31 00:41:45,164:INFO:Creating metrics dataframe
2024-07-31 00:41:45,165:INFO:Uploading results into container
2024-07-31 00:41:45,165:INFO:Uploading model into container now
2024-07-31 00:41:45,166:INFO:_master_model_container: 11
2024-07-31 00:41:45,166:INFO:_display_container: 2
2024-07-31 00:41:45,166:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-31 00:41:45,166:INFO:create_model() successfully completed......................................
2024-07-31 00:41:45,220:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:45,220:INFO:Creating metrics dataframe
2024-07-31 00:41:45,225:INFO:Initializing Extra Trees Classifier
2024-07-31 00:41:45,225:INFO:Total runtime is 0.09548923571904501 minutes
2024-07-31 00:41:45,226:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:45,226:INFO:Initializing create_model()
2024-07-31 00:41:45,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:45,226:INFO:Checking exceptions
2024-07-31 00:41:45,226:INFO:Importing libraries
2024-07-31 00:41:45,226:INFO:Copying training dataset
2024-07-31 00:41:45,229:INFO:Defining folds
2024-07-31 00:41:45,229:INFO:Declaring metric variables
2024-07-31 00:41:45,230:INFO:Importing untrained model
2024-07-31 00:41:45,232:INFO:Extra Trees Classifier Imported successfully
2024-07-31 00:41:45,234:INFO:Starting cross validation
2024-07-31 00:41:45,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:45,398:INFO:Calculating mean and std
2024-07-31 00:41:45,399:INFO:Creating metrics dataframe
2024-07-31 00:41:45,400:INFO:Uploading results into container
2024-07-31 00:41:45,400:INFO:Uploading model into container now
2024-07-31 00:41:45,400:INFO:_master_model_container: 12
2024-07-31 00:41:45,400:INFO:_display_container: 2
2024-07-31 00:41:45,400:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1999, verbose=0,
                     warm_start=False)
2024-07-31 00:41:45,400:INFO:create_model() successfully completed......................................
2024-07-31 00:41:45,465:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:45,465:INFO:Creating metrics dataframe
2024-07-31 00:41:45,471:INFO:Initializing Extreme Gradient Boosting
2024-07-31 00:41:45,471:INFO:Total runtime is 0.09959069887797038 minutes
2024-07-31 00:41:45,473:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:45,473:INFO:Initializing create_model()
2024-07-31 00:41:45,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:45,473:INFO:Checking exceptions
2024-07-31 00:41:45,473:INFO:Importing libraries
2024-07-31 00:41:45,473:INFO:Copying training dataset
2024-07-31 00:41:45,476:INFO:Defining folds
2024-07-31 00:41:45,476:INFO:Declaring metric variables
2024-07-31 00:41:45,477:INFO:Importing untrained model
2024-07-31 00:41:45,479:INFO:Extreme Gradient Boosting Imported successfully
2024-07-31 00:41:45,481:INFO:Starting cross validation
2024-07-31 00:41:45,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:45,670:INFO:Calculating mean and std
2024-07-31 00:41:45,671:INFO:Creating metrics dataframe
2024-07-31 00:41:45,672:INFO:Uploading results into container
2024-07-31 00:41:45,672:INFO:Uploading model into container now
2024-07-31 00:41:45,672:INFO:_master_model_container: 13
2024-07-31 00:41:45,672:INFO:_display_container: 2
2024-07-31 00:41:45,672:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, gamma=None,
              gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, n_estimators=100, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic',
              predictor=None, random_state=1999, reg_alpha=None, ...)
2024-07-31 00:41:45,672:INFO:create_model() successfully completed......................................
2024-07-31 00:41:45,730:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:45,730:INFO:Creating metrics dataframe
2024-07-31 00:41:45,735:INFO:Initializing Light Gradient Boosting Machine
2024-07-31 00:41:45,735:INFO:Total runtime is 0.10399915377298992 minutes
2024-07-31 00:41:45,737:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:45,737:INFO:Initializing create_model()
2024-07-31 00:41:45,737:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:45,737:INFO:Checking exceptions
2024-07-31 00:41:45,737:INFO:Importing libraries
2024-07-31 00:41:45,737:INFO:Copying training dataset
2024-07-31 00:41:45,740:INFO:Defining folds
2024-07-31 00:41:45,740:INFO:Declaring metric variables
2024-07-31 00:41:45,741:INFO:Importing untrained model
2024-07-31 00:41:45,742:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-31 00:41:45,745:INFO:Starting cross validation
2024-07-31 00:41:45,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:46,292:INFO:Calculating mean and std
2024-07-31 00:41:46,293:INFO:Creating metrics dataframe
2024-07-31 00:41:46,294:INFO:Uploading results into container
2024-07-31 00:41:46,294:INFO:Uploading model into container now
2024-07-31 00:41:46,294:INFO:_master_model_container: 14
2024-07-31 00:41:46,295:INFO:_display_container: 2
2024-07-31 00:41:46,295:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1999, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-31 00:41:46,295:INFO:create_model() successfully completed......................................
2024-07-31 00:41:46,354:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:46,354:INFO:Creating metrics dataframe
2024-07-31 00:41:46,358:INFO:Initializing CatBoost Classifier
2024-07-31 00:41:46,358:INFO:Total runtime is 0.11437824964523316 minutes
2024-07-31 00:41:46,360:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:46,360:INFO:Initializing create_model()
2024-07-31 00:41:46,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:46,360:INFO:Checking exceptions
2024-07-31 00:41:46,360:INFO:Importing libraries
2024-07-31 00:41:46,360:INFO:Copying training dataset
2024-07-31 00:41:46,363:INFO:Defining folds
2024-07-31 00:41:46,363:INFO:Declaring metric variables
2024-07-31 00:41:46,364:INFO:Importing untrained model
2024-07-31 00:41:46,365:INFO:CatBoost Classifier Imported successfully
2024-07-31 00:41:46,368:INFO:Starting cross validation
2024-07-31 00:41:46,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:48,093:INFO:Calculating mean and std
2024-07-31 00:41:48,094:INFO:Creating metrics dataframe
2024-07-31 00:41:48,094:INFO:Uploading results into container
2024-07-31 00:41:48,095:INFO:Uploading model into container now
2024-07-31 00:41:48,095:INFO:_master_model_container: 15
2024-07-31 00:41:48,095:INFO:_display_container: 2
2024-07-31 00:41:48,095:INFO:<catboost.core.CatBoostClassifier object at 0x359843610>
2024-07-31 00:41:48,095:INFO:create_model() successfully completed......................................
2024-07-31 00:41:48,155:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:48,155:INFO:Creating metrics dataframe
2024-07-31 00:41:48,160:INFO:Initializing Dummy Classifier
2024-07-31 00:41:48,160:INFO:Total runtime is 0.14440815051396688 minutes
2024-07-31 00:41:48,161:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:48,162:INFO:Initializing create_model()
2024-07-31 00:41:48,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1045c1e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:48,162:INFO:Checking exceptions
2024-07-31 00:41:48,162:INFO:Importing libraries
2024-07-31 00:41:48,162:INFO:Copying training dataset
2024-07-31 00:41:48,165:INFO:Defining folds
2024-07-31 00:41:48,165:INFO:Declaring metric variables
2024-07-31 00:41:48,166:INFO:Importing untrained model
2024-07-31 00:41:48,168:INFO:Dummy Classifier Imported successfully
2024-07-31 00:41:48,171:INFO:Starting cross validation
2024-07-31 00:41:48,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:48,261:INFO:Calculating mean and std
2024-07-31 00:41:48,262:INFO:Creating metrics dataframe
2024-07-31 00:41:48,263:INFO:Uploading results into container
2024-07-31 00:41:48,263:INFO:Uploading model into container now
2024-07-31 00:41:48,263:INFO:_master_model_container: 16
2024-07-31 00:41:48,263:INFO:_display_container: 2
2024-07-31 00:41:48,263:INFO:DummyClassifier(constant=None, random_state=1999, strategy='prior')
2024-07-31 00:41:48,263:INFO:create_model() successfully completed......................................
2024-07-31 00:41:48,317:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:48,317:INFO:Creating metrics dataframe
2024-07-31 00:41:48,326:INFO:Initializing create_model()
2024-07-31 00:41:48,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:48,326:INFO:Checking exceptions
2024-07-31 00:41:48,327:INFO:Importing libraries
2024-07-31 00:41:48,327:INFO:Copying training dataset
2024-07-31 00:41:48,330:INFO:Defining folds
2024-07-31 00:41:48,330:INFO:Declaring metric variables
2024-07-31 00:41:48,330:INFO:Importing untrained model
2024-07-31 00:41:48,330:INFO:Declaring custom model
2024-07-31 00:41:48,330:INFO:Logistic Regression Imported successfully
2024-07-31 00:41:48,331:INFO:Cross validation set to False
2024-07-31 00:41:48,331:INFO:Fitting Model
2024-07-31 00:41:48,349:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-31 00:41:48,349:INFO:create_model() successfully completed......................................
2024-07-31 00:41:48,416:INFO:_master_model_container: 16
2024-07-31 00:41:48,416:INFO:_display_container: 2
2024-07-31 00:41:48,416:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-31 00:41:48,416:INFO:compare_models() successfully completed......................................
2024-07-31 00:41:48,416:INFO:Initializing create_model()
2024-07-31 00:41:48,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:48,416:INFO:Checking exceptions
2024-07-31 00:41:48,422:INFO:Importing libraries
2024-07-31 00:41:48,422:INFO:Copying training dataset
2024-07-31 00:41:48,425:INFO:Defining folds
2024-07-31 00:41:48,425:INFO:Declaring metric variables
2024-07-31 00:41:48,427:INFO:Importing untrained model
2024-07-31 00:41:48,428:INFO:Logistic Regression Imported successfully
2024-07-31 00:41:48,431:INFO:Starting cross validation
2024-07-31 00:41:48,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:48,510:INFO:Calculating mean and std
2024-07-31 00:41:48,510:INFO:Creating metrics dataframe
2024-07-31 00:41:48,512:INFO:Finalizing model
2024-07-31 00:41:48,532:INFO:Uploading results into container
2024-07-31 00:41:48,533:INFO:Uploading model into container now
2024-07-31 00:41:48,537:INFO:_master_model_container: 17
2024-07-31 00:41:48,537:INFO:_display_container: 3
2024-07-31 00:41:48,537:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-31 00:41:48,537:INFO:create_model() successfully completed......................................
2024-07-31 00:41:48,592:INFO:Initializing tune_model()
2024-07-31 00:41:48,593:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>)
2024-07-31 00:41:48,593:INFO:Checking exceptions
2024-07-31 00:41:48,599:INFO:Copying training dataset
2024-07-31 00:41:48,601:INFO:Checking base model
2024-07-31 00:41:48,601:INFO:Base model : Logistic Regression
2024-07-31 00:41:48,603:INFO:Declaring metric variables
2024-07-31 00:41:48,604:INFO:Defining Hyperparameters
2024-07-31 00:41:48,666:INFO:Tuning with n_jobs=-1
2024-07-31 00:41:48,666:INFO:Initializing RandomizedSearchCV
2024-07-31 00:41:48,990:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 1.023}
2024-07-31 00:41:48,990:INFO:Hyperparameter search completed
2024-07-31 00:41:48,990:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:48,990:INFO:Initializing create_model()
2024-07-31 00:41:48,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x353461e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 1.023})
2024-07-31 00:41:48,990:INFO:Checking exceptions
2024-07-31 00:41:48,990:INFO:Importing libraries
2024-07-31 00:41:48,990:INFO:Copying training dataset
2024-07-31 00:41:48,992:INFO:Defining folds
2024-07-31 00:41:48,992:INFO:Declaring metric variables
2024-07-31 00:41:48,994:INFO:Importing untrained model
2024-07-31 00:41:48,994:INFO:Declaring custom model
2024-07-31 00:41:48,995:INFO:Logistic Regression Imported successfully
2024-07-31 00:41:48,998:INFO:Starting cross validation
2024-07-31 00:41:48,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:49,054:INFO:Calculating mean and std
2024-07-31 00:41:49,054:INFO:Creating metrics dataframe
2024-07-31 00:41:49,056:INFO:Finalizing model
2024-07-31 00:41:49,076:INFO:Uploading results into container
2024-07-31 00:41:49,077:INFO:Uploading model into container now
2024-07-31 00:41:49,077:INFO:_master_model_container: 18
2024-07-31 00:41:49,077:INFO:_display_container: 4
2024-07-31 00:41:49,077:INFO:LogisticRegression(C=1.023, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-31 00:41:49,077:INFO:create_model() successfully completed......................................
2024-07-31 00:41:49,133:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:49,133:INFO:choose_better activated
2024-07-31 00:41:49,134:INFO:SubProcess create_model() called ==================================
2024-07-31 00:41:49,135:INFO:Initializing create_model()
2024-07-31 00:41:49,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:49,135:INFO:Checking exceptions
2024-07-31 00:41:49,135:INFO:Importing libraries
2024-07-31 00:41:49,135:INFO:Copying training dataset
2024-07-31 00:41:49,138:INFO:Defining folds
2024-07-31 00:41:49,138:INFO:Declaring metric variables
2024-07-31 00:41:49,138:INFO:Importing untrained model
2024-07-31 00:41:49,138:INFO:Declaring custom model
2024-07-31 00:41:49,138:INFO:Logistic Regression Imported successfully
2024-07-31 00:41:49,138:INFO:Starting cross validation
2024-07-31 00:41:49,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-31 00:41:49,202:INFO:Calculating mean and std
2024-07-31 00:41:49,203:INFO:Creating metrics dataframe
2024-07-31 00:41:49,203:INFO:Finalizing model
2024-07-31 00:41:49,221:INFO:Uploading results into container
2024-07-31 00:41:49,221:INFO:Uploading model into container now
2024-07-31 00:41:49,221:INFO:_master_model_container: 19
2024-07-31 00:41:49,221:INFO:_display_container: 5
2024-07-31 00:41:49,222:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-31 00:41:49,222:INFO:create_model() successfully completed......................................
2024-07-31 00:41:49,276:INFO:SubProcess create_model() end ==================================
2024-07-31 00:41:49,277:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.7839
2024-07-31 00:41:49,277:INFO:LogisticRegression(C=1.023, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.7839
2024-07-31 00:41:49,277:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-07-31 00:41:49,277:INFO:choose_better completed
2024-07-31 00:41:49,277:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-31 00:41:49,281:INFO:_master_model_container: 19
2024-07-31 00:41:49,281:INFO:_display_container: 4
2024-07-31 00:41:49,281:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-31 00:41:49,282:INFO:tune_model() successfully completed......................................
2024-07-31 00:41:49,339:INFO:Initializing finalize_model()
2024-07-31 00:41:49,340:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-07-31 00:41:49,340:INFO:Finalizing LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-31 00:41:49,342:INFO:Initializing create_model()
2024-07-31 00:41:49,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1999, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-07-31 00:41:49,342:INFO:Checking exceptions
2024-07-31 00:41:49,343:INFO:Importing libraries
2024-07-31 00:41:49,343:INFO:Copying training dataset
2024-07-31 00:41:49,343:INFO:Defining folds
2024-07-31 00:41:49,343:INFO:Declaring metric variables
2024-07-31 00:41:49,343:INFO:Importing untrained model
2024-07-31 00:41:49,344:INFO:Declaring custom model
2024-07-31 00:41:49,344:INFO:Logistic Regression Imported successfully
2024-07-31 00:41:49,344:INFO:Cross validation set to False
2024-07-31 00:41:49,344:INFO:Fitting Model
2024-07-31 00:41:49,370:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1999,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-31 00:41:49,370:INFO:create_model() successfully completed......................................
2024-07-31 00:41:49,426:INFO:_master_model_container: 19
2024-07-31 00:41:49,426:INFO:_display_container: 4
2024-07-31 00:41:49,432:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1999,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-31 00:41:49,432:INFO:finalize_model() successfully completed......................................
2024-07-31 00:41:49,501:INFO:Initializing plot_model()
2024-07-31 00:41:49,502:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1999,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, system=True)
2024-07-31 00:41:49,502:INFO:Checking exceptions
2024-07-31 00:41:49,504:INFO:Preloading libraries
2024-07-31 00:41:49,504:INFO:Copying training dataset
2024-07-31 00:41:49,504:INFO:Plot type: feature
2024-07-31 00:41:49,643:INFO:Visual Rendered Successfully
2024-07-31 00:41:49,719:INFO:plot_model() successfully completed......................................
2024-07-31 00:41:49,754:INFO:Initializing evaluate_model()
2024-07-31 00:41:49,754:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1999,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-07-31 00:41:49,780:INFO:Initializing plot_model()
2024-07-31 00:41:49,780:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1999,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, system=True)
2024-07-31 00:41:49,781:INFO:Checking exceptions
2024-07-31 00:41:49,784:INFO:Preloading libraries
2024-07-31 00:41:49,784:INFO:Copying training dataset
2024-07-31 00:41:49,784:INFO:Plot type: pipeline
2024-07-31 00:41:49,873:INFO:Visual Rendered Successfully
2024-07-31 00:41:49,934:INFO:plot_model() successfully completed......................................
2024-07-31 00:41:49,947:INFO:Initializing predict_model()
2024-07-31 00:41:49,948:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1999,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x353651940>)
2024-07-31 00:41:49,948:INFO:Checking exceptions
2024-07-31 00:41:49,948:INFO:Preloading libraries
2024-07-31 00:41:49,949:INFO:Set up data.
2024-07-31 00:41:49,953:INFO:Set up index.
2024-07-31 00:41:52,767:INFO:Initializing plot_model()
2024-07-31 00:41:52,767:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Family_History', 'Age', 'Q1',
                                             'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7',
                                             'Q8', 'Q9', 'Q10', 'Q11', 'Q12',
                                             'Q13', 'Q14', 'Q15', 'Q16', 'Q17',
                                             'Q18', 'Q19', 'Q20', 'Q21', 'Q22',
                                             'Q23', 'language_label'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              k...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1999,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x1048258b0>, system=True)
2024-07-31 00:41:52,767:INFO:Checking exceptions
2024-07-31 00:41:52,769:INFO:Preloading libraries
2024-07-31 00:41:52,770:INFO:Copying training dataset
2024-07-31 00:41:52,770:INFO:Plot type: auc
2024-07-31 00:41:52,866:INFO:Fitting Model
2024-07-31 00:41:52,871:WARNING:/Users/jeahyukjeong/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-07-31 00:41:52,871:INFO:Scoring test/hold-out set
2024-07-31 00:41:52,956:INFO:Visual Rendered Successfully
2024-07-31 00:41:53,016:INFO:plot_model() successfully completed......................................
