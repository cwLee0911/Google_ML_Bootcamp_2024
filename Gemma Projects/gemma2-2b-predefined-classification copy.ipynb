{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-04T09:04:50.382701Z","iopub.status.busy":"2024-09-04T09:04:50.382347Z","iopub.status.idle":"2024-09-04T09:04:56.247711Z","shell.execute_reply":"2024-09-04T09:04:56.246690Z","shell.execute_reply.started":"2024-09-04T09:04:50.382667Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# 라이브러리 불러오기\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import os\n","\n","import tqdm\n","\n","import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.utils.data import Dataset\n","from sklearn.metrics import roc_auc_score, average_precision_score\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","import seaborn as sns\n","\n","from transformers import Trainer\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import TrainingArguments\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","True\n"]}],"source":["import torch\n","print(torch.backends.mps.is_available())\n","print(torch.backends.mps.is_built())"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import torch\n","import pandas as pd\n","from datasets import Dataset, load_dataset\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n","from transformers import (\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    AutoModelForSequenceClassification, \n","    TrainingArguments, \n","    Trainer,\n","    EarlyStoppingCallback,\n","    DataCollatorWithPadding)\n","\n","#import bitsandbytes as bnb\n","\n","#import evaluate\n","import numpy as np\n","\n","import random"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["access_token = 'ß'\n","mps_device = torch.device(\"mps\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Token is valid (permission: read).\n","Your token has been saved in your configured git credential helpers (osxkeychain).\n","Your token has been saved to /Users/jeahyukjeong/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login(access_token, add_to_git_credential=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T09:04:56.249850Z","iopub.status.busy":"2024-09-04T09:04:56.249439Z","iopub.status.idle":"2024-09-04T09:04:56.289632Z","shell.execute_reply":"2024-09-04T09:04:56.288787Z","shell.execute_reply.started":"2024-09-04T09:04:56.249815Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["QCHAT label_encoded counts:  encoded_label\n","1    110\n","0     44\n","Name: count, dtype: int64\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Class/ASD Traits</th>\n","      <th>text</th>\n","      <th>encoded_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>, , , , , , , , ,</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>, , , , , , , , ,</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>, , , , , , , , ,</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>, , , , , , , , ,</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>, , , , , , , , ,</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Class/ASD Traits                text  encoded_label\n","0                 0   , , , , , , , , ,              0\n","1                 0   , , , , , , , , ,              0\n","2                 0   , , , , , , , , ,              0\n","3                 0   , , , , , , , , ,              0\n","4                 0   , , , , , , , , ,              0"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# 데이터 불러오기\n","\n","data_total = pd.read_csv('./output/QCHAT_T_ASD_total_First.csv')\n","data_total=data_total[['Class/ASD Traits','text']] # 데이터셋에서 Class/ASD Traits 와 text column만 사용\n","\n","# target label encoding\n","Q_ASD_mapping = {\n","    'No': 0, # TD\n","    'Yes': 1, # ASD\n","}\n","\n","num_mapping = {\n","    0: 'No', # TD\n","    1: 'Yes', # ASD\n","\n","}\n","\n","data_total['encoded_label'] = data_total['Class/ASD Traits'].replace(Q_ASD_mapping)\n","\n","# 결과\n","print(\"QCHAT label_encoded counts: \", data_total.encoded_label.value_counts())\n","data_total.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T09:04:56.290914Z","iopub.status.busy":"2024-09-04T09:04:56.290640Z","iopub.status.idle":"2024-09-04T09:04:56.315055Z","shell.execute_reply":"2024-09-04T09:04:56.314281Z","shell.execute_reply.started":"2024-09-04T09:04:56.290883Z"},"trusted":true},"outputs":[],"source":["# 시드값 설정\n","\n","if torch.cuda.is_available(): \n","    print(\"GPU is available\")\n","\n","#set random seed \n","def set_seed(random_seed):\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    # torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(random_seed)\n","    random.seed(random_seed)\n","    \n","random_seed = 42\n","set_seed(random_seed)\n","SEED = 42"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T09:04:56.317619Z","iopub.status.busy":"2024-09-04T09:04:56.317340Z","iopub.status.idle":"2024-09-04T09:04:57.263497Z","shell.execute_reply":"2024-09-04T09:04:57.262704Z","shell.execute_reply.started":"2024-09-04T09:04:56.317587Z"},"trusted":true},"outputs":[],"source":["# X: input variables, y: target variable\n","X = data_total.drop('encoded_label', axis=1)\n","y = data_total['encoded_label']\n","\n","# train-test split(7:3)\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n","\n","train_and_validation_df = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n","test_df = pd.concat([X_test, y_test], axis=1).reset_index(drop=True) # test dataset\n","\n","# train-validation split(8:2)\n","\n","# X: input variables, y: target variable\n","X = train_and_validation_df.drop('encoded_label', axis=1)\n","y = train_and_validation_df['encoded_label']\n","\n","# Split the training data into training and validation sets\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n","\n","train_df = pd.concat([X_train, y_train], axis=1).reset_index(drop=True) # training dataset\n","valid_df = pd.concat([X_valid, y_valid], axis=1).reset_index(drop=True) # validation dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T09:04:57.264856Z","iopub.status.busy":"2024-09-04T09:04:57.264548Z","iopub.status.idle":"2024-09-04T09:04:57.272270Z","shell.execute_reply":"2024-09-04T09:04:57.271213Z","shell.execute_reply.started":"2024-09-04T09:04:57.264822Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["size of train dataset:  85\n","size of validation dataset:  22\n","size of test dataset:  47\n"]}],"source":["print(\"size of train dataset: \", len(train_df))\n","print(\"size of validation dataset: \", len(valid_df))\n","print(\"size of test dataset: \", len(test_df))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T09:06:21.028288Z","iopub.status.busy":"2024-09-04T09:06:21.027601Z","iopub.status.idle":"2024-09-04T09:06:21.049415Z","shell.execute_reply":"2024-09-04T09:06:21.048404Z","shell.execute_reply.started":"2024-09-04T09:06:21.028250Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["# Tokenization에 사용될 모델 \n","tokenizer = AutoTokenizer.from_pretrained('google/gemma-2-2b')\n","\n","# train set tokenization\n","encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True, max_length=32)\n","train_labels = train_df['encoded_label'].tolist()\n","train_input_ids = encodings['input_ids']\n","train_attention_masks = encodings['attention_mask']\n","\n","# validation set tokenization\n","encodings = tokenizer(valid_df['text'].tolist(), truncation=True, padding=True, max_length=32)\n","valid_labels = valid_df['encoded_label'].tolist()\n","valid_input_ids = encodings['input_ids']\n","valid_attention_masks = encodings['attention_mask']\n","\n","# test set tokenization\n","encodings = tokenizer(test_df['text'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n","test_input_ids = encodings['input_ids']\n","test_attention_masks = encodings['attention_mask']"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["text example from train BEFORE tokenization: \n"," , , , , , , , , ,play impairment stares blankly at play objects rather than manipulating them\n"]}],"source":["# Before\n","print(\"text example from train BEFORE tokenization: \")\n","print(train_df['text'][0])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T09:06:24.960947Z","iopub.status.busy":"2024-09-04T09:06:24.960222Z","iopub.status.idle":"2024-09-04T09:06:32.538593Z","shell.execute_reply":"2024-09-04T09:06:32.537195Z","shell.execute_reply.started":"2024-09-04T09:06:24.960907Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["text example from train AFTER tokenization: \n","Input Ids:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1688, 1688, 1688, 1688, 1688, 1688, 1688, 1688, 1688, 1752, 61551, 124686, 15601, 605, 696, 1554, 9113, 4644, 1178, 111076, 1174]\n","attention mask:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}],"source":["# After\n","print(\"text example from train AFTER tokenization: \")\n","print(\"Input Ids: \", train_input_ids[0])\n","print(\"attention mask: \", train_attention_masks[0])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# training에 사용하기 위해 데이터 타입 전환\n","\n","# Training에 사용될 데이터 class\n","class QCHATDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, input_ids, attention_masks, labels):\n","        self.input_ids = input_ids\n","        self.attention_masks = attention_masks\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        \n","        # training 과정에서 데이터가 사용될 때 tensor 타입으로 사용되도록 합니다. \n","        return {\n","            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.int),\n","            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.int),\n","            'labels': torch.tensor(self.labels[idx], dtype=torch.int)\n","        }\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","\n","# train set\n","train_dataset = QCHATDataset(train_input_ids, train_attention_masks, train_labels)\n","# Validation set\n","validation_dataset = QCHATDataset(valid_input_ids, valid_attention_masks, valid_labels)\n","# test dataset\n","test_dataset = QCHATDataset(test_input_ids, test_attention_masks, test_df['encoded_label'].tolist())"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["torch.int32"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["torch.int"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["'\\nimport torch\\nfrom transformers import TrainingArguments\\n\\n\\nclass TrainingArgumentsWithMPSSupport(TrainingArguments):\\n\\n    @property\\n    def device(self) -> torch.device:\\n        if torch.cuda.is_available():\\n            return torch.device(\"cuda\")\\n        elif torch.backends.mps.is_available():\\n            return torch.device(\"mps\")\\n        else:\\n            return torch.device(\"cpu\")\\n\\n'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["#https://github.com/huggingface/transformers/issues/17971\n","#os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n","\"\"\"\n","import torch\n","from transformers import TrainingArguments\n","\n","\n","class TrainingArgumentsWithMPSSupport(TrainingArguments):\n","\n","    @property\n","    def device(self) -> torch.device:\n","        if torch.cuda.is_available():\n","            return torch.device(\"cuda\")\n","        elif torch.backends.mps.is_available():\n","            return torch.device(\"mps\")\n","        else:\n","            return torch.device(\"cpu\")\n","\n","\"\"\""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[2024-09-09 13:11:09,980] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to mps (auto detect)\n"]},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","W0909 13:11:10.448404 8332671680 torch/distributed/elastic/multiprocessing/redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  8.86it/s]\n","Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-2b and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["import deepspeed\n","\n","# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","# os.environ['TORCH_USE_CUDA_DSA']='1'\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","\n","# RoBERTa Classification 기본 모델을 불러옵니다.\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"google/gemma-2-2b\", \n","    num_labels=2,\n","    #device_map = 'auto',\n","    #id2label = Q_ASD_mapping,\n","    #label2id = num_mapping\n","    )\n","\n","\n","# Training에 사용될 hyperparameter을 설정해줍니다.\n","training_args = TrainingArguments(\n","    output_dir='./output', #         # output directory for model checkpoints\n","    num_train_epochs=5,              # number of training epochs\n","    per_device_train_batch_size = 1,  # batch size for training\n","    per_device_eval_batch_size=1,   # batch size for evaluation\n","    warmup_steps=0,                # number of warmup steps\n","    weight_decay=1e-8,               # strength of weight decay\n","    logging_dir='./Gemma/log',            # directory for storing logs\n","    logging_steps=10,              # log saving step. 100\n","    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`,\n","    learning_rate=2e-5,              # learning rate\n","    #gradient_accumulation_steps=8,\n","    #deepspeed=\"./deepspeed.json\",\n","    #fp16=False,\n","    #save_steps=100,\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Training에 사용할 evaluation metrics를 설정해줍니다.\n","\n","def compute_metrics_multiclass(p, num_classes=2):  # num_classes는 예시 값입니다. 실제 클래스 수로 변경하세요.\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    # Multiclass\n","    f1 = f1_score(labels, predictions, average='macro')\n","    precision = precision_score(labels, predictions, average='macro')\n","    recall = recall_score(labels, predictions, average='macro')\n","    acc = accuracy_score(labels, predictions)\n","\n","    # Treat each class as a binary classification\n","    labels_binarized = label_binarize(labels, classes=range(num_classes))\n","    predictions_binarized = label_binarize(predictions, classes=range(num_classes))\n","\n","    # Multiclass AUROC , Average Precision\n","    auroc = roc_auc_score(labels_binarized, predictions_binarized, multi_class='ovr')\n","    avgprc = average_precision_score(labels_binarized, predictions_binarized)\n","\n","    return {\n","        \"acc\": acc, \n","        \"f1\": f1, \n","        \"precision\": precision, \n","        \"recall\": recall, \n","        \"auroc\": auroc, \n","        \"avgprc\": avgprc\n","    }\n","\n","def compute_metrics_wrapper(p):\n","    return compute_metrics_multiclass(p, num_classes=2) #0,1\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/425 [00:00<?, ?it/s]"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/torch/optim/adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    178\u001b[0m         group,\n\u001b[1;32m    179\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         state_steps,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 188\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/torch/optim/adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 340\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/torch/optim/adamw.py:471\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 471\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    473\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n","\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 41.56 GB, other allocations: 2.21 GB, max allowed: 45.90 GB). Tried to allocate 2.20 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics_wrapper  \u001b[38;5;66;03m# We will define compute_metrics function later\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Training을 시작합니다.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/transformers/trainer.py:2341\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2338\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2339\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[0;32m-> 2341\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2345\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/accelerate/optimizer.py:172\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/anaconda3/envs/RoBERTa2/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Training에 필요한 데이터셋, model, evaluation_metrics, hyperparameter 등을 주어줍니다.\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    compute_metrics=compute_metrics_wrapper  # We will define compute_metrics function later\n",")\n","\n","# Training을 시작합니다.\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluation \n","trainer.evaluate()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5637661,"sourceId":9309180,"sourceType":"datasetVersion"},{"datasetId":5640513,"sourceId":9313319,"sourceType":"datasetVersion"},{"modelId":76277,"modelInstanceId":72253,"sourceId":104625,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
