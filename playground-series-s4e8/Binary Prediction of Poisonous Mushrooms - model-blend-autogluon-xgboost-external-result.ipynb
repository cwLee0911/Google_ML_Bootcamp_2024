{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"},{"sourceId":9255459,"sourceType":"datasetVersion","datasetId":5599697},{"sourceId":191407989,"sourceType":"kernelVersion"},{"sourceId":192934997,"sourceType":"kernelVersion"},{"sourceId":192998056,"sourceType":"kernelVersion"},{"sourceId":194042613,"sourceType":"kernelVersion"},{"sourceId":194743054,"sourceType":"kernelVersion"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T22:31:28.310893Z","iopub.execute_input":"2024-08-31T22:31:28.311156Z","iopub.status.idle":"2024-08-31T22:31:28.315856Z","shell.execute_reply.started":"2024-08-31T22:31:28.311130Z","shell.execute_reply":"2024-08-31T22:31:28.314929Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"%%time \n\nprediction_data = pd.read_csv(f\"/kaggle/input/playground-series-s4e8/sample_submission.csv\", \n                     index_col = [\"id\"]).drop(\"class\", axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:36:27.989980Z","iopub.execute_input":"2024-08-31T22:36:27.990282Z","iopub.status.idle":"2024-08-31T22:36:28.397438Z","shell.execute_reply.started":"2024-08-31T22:36:27.990257Z","shell.execute_reply":"2024-08-31T22:36:28.396429Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 397 ms, sys: 5.89 ms, total: 403 ms\nWall time: 402 ms\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"<h2>External Results</h2>\n\n1. https://www.kaggle.com/code/arunklenin/ps4e8-binary-class-mathews-correlation-coeff\n2. https://www.kaggle.com/code/mobinapoulaei/autogloun-t8-dslanders\n3. https://www.kaggle.com/code/olegpushs/automl-grand-prix-8th-place-notebook\n4. https://www.kaggle.com/code/samiraalipour/automl-poisonous-mushrooms-t6-dslanders\n5. https://www.kaggle.com/code/adaluodaa/mario-s-nightmare-denselight-0-990\n\n<h2>Internal Results</h2>\n\n1. Autogluon with stack level = 2(15 hours)\n2. XGBoost with manually generated hyperparameters + One-hot Encoding + SHAP + IsolationForeset(16min)\n","metadata":{}},{"cell_type":"code","source":"%%time \n#External Results\n\nprediction_data[\"sub1\"] = pd.read_csv(f\"/kaggle/input/ps4e8-binary-class-mathews-correlation-coeff/submission.csv\").iloc[:,-1].values.flatten()\n# 98521 - 3\nprediction_data[\"sub2\"] = pd.read_csv(f\"/kaggle/input/autogloun-t8-dslanders/submission.csv\").iloc[:,-1].values.flatten()\n# 98530 - 1\nprediction_data[\"sub3\"] = pd.read_csv(f\"/kaggle/input/ex1-pss4e8-autogluon/[AutoML Grand Prix] Team GD Autogluon,mcc.csv\").iloc[:,-1].values.flatten()\n# 98517 - 5\nprediction_data[\"sub4\"] = pd.read_csv(f\"/kaggle/input/automl-poisonous-mushrooms-t6-dslanders/submission.csv\").iloc[:,-1].values.flatten()\n# 98520 - 4\nprediction_data[\"sub5\"] = pd.read_csv(f\"/kaggle/input/mario-s-nightmare-15-th-place-solution/submission.csv\").iloc[:,-1].values.flatten()\n# 98528 - 2\n\nprint()\ndisplay(prediction_data.head(10).style.set_caption(f\"Submission file with components\"))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T22:36:29.993722Z","iopub.execute_input":"2024-08-31T22:36:29.994046Z","iopub.status.idle":"2024-08-31T22:36:32.016593Z","shell.execute_reply.started":"2024-08-31T22:36:29.994018Z","shell.execute_reply":"2024-08-31T22:36:32.015630Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7ad0456f0850>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_df6a7\">\n  <caption>Submission file with components</caption>\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_df6a7_level0_col0\" class=\"col_heading level0 col0\" >sub1</th>\n      <th id=\"T_df6a7_level0_col1\" class=\"col_heading level0 col1\" >sub2</th>\n      <th id=\"T_df6a7_level0_col2\" class=\"col_heading level0 col2\" >sub3</th>\n      <th id=\"T_df6a7_level0_col3\" class=\"col_heading level0 col3\" >sub4</th>\n      <th id=\"T_df6a7_level0_col4\" class=\"col_heading level0 col4\" >sub5</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >id</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n      <th class=\"blank col3\" >&nbsp;</th>\n      <th class=\"blank col4\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_df6a7_level0_row0\" class=\"row_heading level0 row0\" >3116945</th>\n      <td id=\"T_df6a7_row0_col0\" class=\"data row0 col0\" >e</td>\n      <td id=\"T_df6a7_row0_col1\" class=\"data row0 col1\" >e</td>\n      <td id=\"T_df6a7_row0_col2\" class=\"data row0 col2\" >e</td>\n      <td id=\"T_df6a7_row0_col3\" class=\"data row0 col3\" >e</td>\n      <td id=\"T_df6a7_row0_col4\" class=\"data row0 col4\" >e</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row1\" class=\"row_heading level0 row1\" >3116946</th>\n      <td id=\"T_df6a7_row1_col0\" class=\"data row1 col0\" >p</td>\n      <td id=\"T_df6a7_row1_col1\" class=\"data row1 col1\" >p</td>\n      <td id=\"T_df6a7_row1_col2\" class=\"data row1 col2\" >p</td>\n      <td id=\"T_df6a7_row1_col3\" class=\"data row1 col3\" >p</td>\n      <td id=\"T_df6a7_row1_col4\" class=\"data row1 col4\" >p</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row2\" class=\"row_heading level0 row2\" >3116947</th>\n      <td id=\"T_df6a7_row2_col0\" class=\"data row2 col0\" >p</td>\n      <td id=\"T_df6a7_row2_col1\" class=\"data row2 col1\" >p</td>\n      <td id=\"T_df6a7_row2_col2\" class=\"data row2 col2\" >p</td>\n      <td id=\"T_df6a7_row2_col3\" class=\"data row2 col3\" >p</td>\n      <td id=\"T_df6a7_row2_col4\" class=\"data row2 col4\" >p</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row3\" class=\"row_heading level0 row3\" >3116948</th>\n      <td id=\"T_df6a7_row3_col0\" class=\"data row3 col0\" >p</td>\n      <td id=\"T_df6a7_row3_col1\" class=\"data row3 col1\" >p</td>\n      <td id=\"T_df6a7_row3_col2\" class=\"data row3 col2\" >p</td>\n      <td id=\"T_df6a7_row3_col3\" class=\"data row3 col3\" >p</td>\n      <td id=\"T_df6a7_row3_col4\" class=\"data row3 col4\" >p</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row4\" class=\"row_heading level0 row4\" >3116949</th>\n      <td id=\"T_df6a7_row4_col0\" class=\"data row4 col0\" >e</td>\n      <td id=\"T_df6a7_row4_col1\" class=\"data row4 col1\" >e</td>\n      <td id=\"T_df6a7_row4_col2\" class=\"data row4 col2\" >e</td>\n      <td id=\"T_df6a7_row4_col3\" class=\"data row4 col3\" >e</td>\n      <td id=\"T_df6a7_row4_col4\" class=\"data row4 col4\" >e</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row5\" class=\"row_heading level0 row5\" >3116950</th>\n      <td id=\"T_df6a7_row5_col0\" class=\"data row5 col0\" >e</td>\n      <td id=\"T_df6a7_row5_col1\" class=\"data row5 col1\" >e</td>\n      <td id=\"T_df6a7_row5_col2\" class=\"data row5 col2\" >e</td>\n      <td id=\"T_df6a7_row5_col3\" class=\"data row5 col3\" >e</td>\n      <td id=\"T_df6a7_row5_col4\" class=\"data row5 col4\" >e</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row6\" class=\"row_heading level0 row6\" >3116951</th>\n      <td id=\"T_df6a7_row6_col0\" class=\"data row6 col0\" >e</td>\n      <td id=\"T_df6a7_row6_col1\" class=\"data row6 col1\" >e</td>\n      <td id=\"T_df6a7_row6_col2\" class=\"data row6 col2\" >e</td>\n      <td id=\"T_df6a7_row6_col3\" class=\"data row6 col3\" >e</td>\n      <td id=\"T_df6a7_row6_col4\" class=\"data row6 col4\" >e</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row7\" class=\"row_heading level0 row7\" >3116952</th>\n      <td id=\"T_df6a7_row7_col0\" class=\"data row7 col0\" >p</td>\n      <td id=\"T_df6a7_row7_col1\" class=\"data row7 col1\" >p</td>\n      <td id=\"T_df6a7_row7_col2\" class=\"data row7 col2\" >p</td>\n      <td id=\"T_df6a7_row7_col3\" class=\"data row7 col3\" >p</td>\n      <td id=\"T_df6a7_row7_col4\" class=\"data row7 col4\" >p</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row8\" class=\"row_heading level0 row8\" >3116953</th>\n      <td id=\"T_df6a7_row8_col0\" class=\"data row8 col0\" >p</td>\n      <td id=\"T_df6a7_row8_col1\" class=\"data row8 col1\" >p</td>\n      <td id=\"T_df6a7_row8_col2\" class=\"data row8 col2\" >p</td>\n      <td id=\"T_df6a7_row8_col3\" class=\"data row8 col3\" >p</td>\n      <td id=\"T_df6a7_row8_col4\" class=\"data row8 col4\" >p</td>\n    </tr>\n    <tr>\n      <th id=\"T_df6a7_level0_row9\" class=\"row_heading level0 row9\" >3116954</th>\n      <td id=\"T_df6a7_row9_col0\" class=\"data row9 col0\" >e</td>\n      <td id=\"T_df6a7_row9_col1\" class=\"data row9 col1\" >e</td>\n      <td id=\"T_df6a7_row9_col2\" class=\"data row9 col2\" >e</td>\n      <td id=\"T_df6a7_row9_col3\" class=\"data row9 col3\" >e</td>\n      <td id=\"T_df6a7_row9_col4\" class=\"data row9 col4\" >e</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}},{"name":"stdout","text":"CPU times: user 1.99 s, sys: 24 ms, total: 2.01 s\nWall time: 2.02 s\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"#Internal Results: XGBoost\n\nimport pandas as pd\nimport numpy as np  \nfrom scipy import stats\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, FunctionTransformer, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.ensemble import IsolationForest\n\nimport shap\n\nrs = 101\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:09:01.347408Z","iopub.execute_input":"2024-08-31T23:09:01.347712Z","iopub.status.idle":"2024-08-31T23:09:01.356986Z","shell.execute_reply.started":"2024-08-31T23:09:01.347686Z","shell.execute_reply":"2024-08-31T23:09:01.356099Z"},"trusted":true},"outputs":[],"execution_count":57},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv')\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:09:02.495055Z","iopub.execute_input":"2024-08-31T23:09:02.495326Z","iopub.status.idle":"2024-08-31T23:09:13.316634Z","shell.execute_reply.started":"2024-08-31T23:09:02.495302Z","shell.execute_reply":"2024-08-31T23:09:13.315738Z"},"trusted":true},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"   id class  cap-diameter cap-shape cap-surface cap-color  \\\n0   0     e          8.80         f           s         u   \n1   1     p          4.51         x           h         o   \n2   2     e          6.94         f           s         b   \n3   3     e          3.88         f           y         g   \n4   4     e          5.85         x           l         w   \n\n  does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n0                    f               a            c          w  ...   \n1                    f               a            c          n  ...   \n2                    f               x            c          w  ...   \n3                    f               s          NaN          g  ...   \n4                    f               d          NaN          w  ...   \n\n   stem-root  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n0        NaN           NaN          w       NaN        NaN        f         f   \n1        NaN             y          o       NaN        NaN        t         z   \n2        NaN             s          n       NaN        NaN        f         f   \n3        NaN           NaN          w       NaN        NaN        f         f   \n4        NaN           NaN          w       NaN        NaN        f         f   \n\n  spore-print-color habitat season  \n0               NaN       d      a  \n1               NaN       d      w  \n2               NaN       l      w  \n3               NaN       d      u  \n4               NaN       g      a  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>cap-diameter</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>does-bruise-or-bleed</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-color</th>\n      <th>...</th>\n      <th>stem-root</th>\n      <th>stem-surface</th>\n      <th>stem-color</th>\n      <th>veil-type</th>\n      <th>veil-color</th>\n      <th>has-ring</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>habitat</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>e</td>\n      <td>8.80</td>\n      <td>f</td>\n      <td>s</td>\n      <td>u</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>p</td>\n      <td>4.51</td>\n      <td>x</td>\n      <td>h</td>\n      <td>o</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>n</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>o</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>z</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>w</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>e</td>\n      <td>6.94</td>\n      <td>f</td>\n      <td>s</td>\n      <td>b</td>\n      <td>f</td>\n      <td>x</td>\n      <td>c</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>s</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>l</td>\n      <td>w</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>e</td>\n      <td>3.88</td>\n      <td>f</td>\n      <td>y</td>\n      <td>g</td>\n      <td>f</td>\n      <td>s</td>\n      <td>NaN</td>\n      <td>g</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>e</td>\n      <td>5.85</td>\n      <td>x</td>\n      <td>l</td>\n      <td>w</td>\n      <td>f</td>\n      <td>d</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>g</td>\n      <td>a</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"df_train_cleaned = df_train.copy()\ndf_test_cleaned = df_test.copy()\n\n# Drop 'id' column\ndf_train_cleaned = df_train_cleaned.drop(['id'], axis=1)\n\n# Define the target column\ntarget_column = 'class'\n\n# ordinal column\nordinal_columns = np.array(['gill-spacing'])\n# ordinal column에서 사용된 데이터의 순서를 정의\ngill_spacing_order = [[ 'f', 'Unknown', 'c', 'd']]\n\n# Select categorical columns, excluding the target column\ncategorical_columns = df_train_cleaned.select_dtypes(include=['object']).columns.drop(target_column)\ncategorical_columns = categorical_columns.drop('gill-spacing')\n\n# Select numerical columns, excluding the target column if it's numerical\nnumerical_columns = df_train_cleaned.select_dtypes(exclude=['object']).columns.drop(target_column, errors='ignore')","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:14:25.989085Z","iopub.execute_input":"2024-08-31T23:14:25.989482Z","iopub.status.idle":"2024-08-31T23:14:28.006687Z","shell.execute_reply.started":"2024-08-31T23:14:25.989446Z","shell.execute_reply":"2024-08-31T23:14:28.005896Z"},"trusted":true},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# Define a function to identify and replace infrequent categories\ndef replace_infrequent_categories(df, column, threshold=70):\n    value_counts = df[column].value_counts()\n    infrequent = value_counts[value_counts <= threshold].index\n    df[column] = df[column].apply(lambda x: \"Unknown\" if x in infrequent else x)\n    return df\n\n# Handle invalid values and infrequent categories for all categorical columns\nfor col in categorical_columns:\n    df_train_cleaned = replace_infrequent_categories(df_train_cleaned, col)\n    df_test_cleaned = replace_infrequent_categories(df_test_cleaned, col)\n\n# ordinal column에도 똑같이 적용\ndf_train_cleaned = replace_infrequent_categories(df_train_cleaned, ordinal_columns[0])\ndf_test_cleaned = replace_infrequent_categories(df_test_cleaned, ordinal_columns[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:16:02.406796Z","iopub.execute_input":"2024-08-31T23:16:02.407089Z","iopub.status.idle":"2024-08-31T23:19:21.338247Z","shell.execute_reply.started":"2024-08-31T23:16:02.407065Z","shell.execute_reply":"2024-08-31T23:19:21.337428Z"},"trusted":true},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# numercal column들의 skewness (데이터의 전체적인 기울기) 계산\ndf_train_cleaned[numerical_columns].apply(lambda x: stats.skew(x.dropna()))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:19:21.339472Z","iopub.execute_input":"2024-08-31T23:19:21.339777Z","iopub.status.idle":"2024-08-31T23:19:21.550282Z","shell.execute_reply.started":"2024-08-31T23:19:21.339739Z","shell.execute_reply":"2024-08-31T23:19:21.549367Z"},"trusted":true},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"cap-diameter    3.972607\nstem-height     1.926681\nstem-width      1.235426\ndtype: float64"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"# Compute medians for numerical columns in the training set\nmedians = df_train_cleaned[numerical_columns].median()\n\n# Fill missing values in the training and testing sets\ndf_train_cleaned[numerical_columns] = df_train_cleaned[numerical_columns].fillna(medians)\ndf_test_cleaned[numerical_columns] = df_test_cleaned[numerical_columns].fillna(medians)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:19:21.551422Z","iopub.execute_input":"2024-08-31T23:19:21.551704Z","iopub.status.idle":"2024-08-31T23:19:21.869863Z","shell.execute_reply.started":"2024-08-31T23:19:21.551680Z","shell.execute_reply":"2024-08-31T23:19:21.868666Z"},"trusted":true},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# Impute any missing values with 'Unknown'\ndf_train_cleaned = df_train_cleaned.fillna(\"Unknown\")\ndf_test_cleaned = df_test_cleaned.fillna(\"Unknown\")","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:19:21.871193Z","iopub.execute_input":"2024-08-31T23:19:21.871537Z","iopub.status.idle":"2024-08-31T23:19:30.742492Z","shell.execute_reply.started":"2024-08-31T23:19:21.871506Z","shell.execute_reply":"2024-08-31T23:19:30.741699Z"},"trusted":true},"outputs":[],"execution_count":66},{"cell_type":"code","source":"#ㅁㄴㅇ\ndf_train_cleaned = df_train_cleaned.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:19:30.743737Z","iopub.execute_input":"2024-08-31T23:19:30.744066Z","iopub.status.idle":"2024-08-31T23:19:36.531815Z","shell.execute_reply.started":"2024-08-31T23:19:30.744039Z","shell.execute_reply":"2024-08-31T23:19:36.531032Z"},"trusted":true},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the target variable\ntrain_encoded_target = label_encoder.fit_transform(df_train_cleaned[['class']])\n\n# Convert categorical columns to 'category' dtype \ndf_train_cleaned[categorical_columns] = df_train_cleaned[categorical_columns].astype('category')\ndf_test_cleaned[categorical_columns] = df_test_cleaned[categorical_columns].astype('category')\n\n# Convert ordinal columns to 'category' dtype \ndf_train_cleaned[ordinal_columns] = df_train_cleaned[ordinal_columns].astype('category')\ndf_test_cleaned[ordinal_columns] = df_test_cleaned[ordinal_columns].astype('category')\n\n# Define the numerical pipeline\nnumerical_pipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('convert_to_float32', FunctionTransformer(lambda x: x.astype(np.float32)))\n])\n\n# Define the categorical pipeline\nordinal_pipeline = Pipeline(steps=[\n    ('ordinal', OrdinalEncoder(dtype=np.int32, handle_unknown='use_encoded_value', unknown_value=-1, categories=gill_spacing_order))\n])\n\n# Define the categorical pipeline\ncategorical_pipeline = Pipeline(steps=[\n    ('onehot', OneHotEncoder(drop='first', dtype=np.int32, handle_unknown='ignore'))\n])\n\n# Combine both numerical and categorical pipelines\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_pipeline, numerical_columns),\n        ('ord', ordinal_pipeline, ordinal_columns),\n        ('cat', categorical_pipeline, categorical_columns)\n    ]\n)\n\n\n# Apply the transformations using the pipeline\ndf_train_encoded = preprocessor.fit_transform(df_train_cleaned)\ndf_test_encoded = preprocessor.transform(df_test_cleaned)\n\n# Ensure outputs are dense arrays\ntrain_encoded_dense = df_train_encoded.toarray()\ntest_encoded_dense = df_test_encoded.toarray()\n\n# Get feature names\nnumerical_feature_names = numerical_columns  # Assuming numerical columns do not change names\nordinal_feature_names = ordinal_columns\ncategorical_feature_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_columns)\n\n# Combine the feature names\nall_feature_names = np.concatenate([numerical_feature_names, ordinal_feature_names, categorical_feature_names])\n\n# Debugging: Print the number of feature names\nprint(\"Number of Features:\", len(all_feature_names))\n\n# Convert the transformed dense arrays back into DataFrames\ndf_train_preprocessed = pd.DataFrame(train_encoded_dense, columns=all_feature_names)\ndf_test_preprocessed = pd.DataFrame(test_encoded_dense, columns=all_feature_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:19:36.533194Z","iopub.execute_input":"2024-08-31T23:19:36.533555Z","iopub.status.idle":"2024-08-31T23:20:28.232650Z","shell.execute_reply.started":"2024-08-31T23:19:36.533521Z","shell.execute_reply":"2024-08-31T23:20:28.231630Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of Features: 120\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"# Apply Isolation Forest for outlier detection\nisolation_forest = IsolationForest(contamination=0.05, random_state=42)\noutlier_labels = isolation_forest.fit_predict(df_train_preprocessed)\n\n# Filter out outliers\nnon_outliers_mask = outlier_labels != -1\ndf_train_preprocessed = df_train_preprocessed[non_outliers_mask]\ntrain_encoded_target = train_encoded_target[non_outliers_mask]","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:20:28.233917Z","iopub.execute_input":"2024-08-31T23:20:28.234293Z","iopub.status.idle":"2024-08-31T23:24:54.490423Z","shell.execute_reply.started":"2024-08-31T23:20:28.234259Z","shell.execute_reply":"2024-08-31T23:24:54.489574Z"},"trusted":true},"outputs":[],"execution_count":69},{"cell_type":"code","source":"\nhigh_negative_shap = ['cap-surface_l', 'gill-color_e', 'cap-color_b', 'gill-color_f', 'veil-color_y', 'stem-color_b', 'ring-type_m', 'stem-color_l']\n# 보류: 'cap-color_o', 'habitat_g', 'cap-surface_y' not working as expected\n# 'gill-attachment_f', 'habitat_l'\n\ndf_train_preprocessed = df_train_preprocessed.drop(high_negative_shap, axis = 1)\ndf_test_preprocessed = df_test_preprocessed.drop(high_negative_shap, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:24:54.491535Z","iopub.execute_input":"2024-08-31T23:24:54.491813Z","iopub.status.idle":"2024-08-31T23:24:56.037278Z","shell.execute_reply.started":"2024-08-31T23:24:54.491785Z","shell.execute_reply":"2024-08-31T23:24:56.036256Z"},"trusted":true},"outputs":[],"execution_count":70},{"cell_type":"code","source":"# Separate features (X) and target variable (y)\nX = df_train_preprocessed\ny = train_encoded_target\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:24:56.038481Z","iopub.execute_input":"2024-08-31T23:24:56.038793Z","iopub.status.idle":"2024-08-31T23:24:57.146920Z","shell.execute_reply.started":"2024-08-31T23:24:56.038743Z","shell.execute_reply":"2024-08-31T23:24:57.146103Z"},"trusted":true},"outputs":[],"execution_count":71},{"cell_type":"code","source":"#duplicate\nparams = {\n    'colsample_bytree': 0.4, \n    'learning_rate': 0.01, \n    'max_depth': 14, \n    'min_child_weight': 1, \n    'n_estimators': 3000, \n    'subsample': 0.9,\n    'use_label_encoder': False,  \n    'eval_metric': 'mlogloss',   \n    'session_id': 112,   \n    'device': 'cuda'\n    # 0.9846626117489504\n}\n\n# Initialize the XGBClassifier with the defined parameters\nxgb_model = XGBClassifier(**params)\n\n# Fit the model to the training data \nxgb_model.fit(X_train, y_train)\n\n# Predict on the test data \ny_pred = xgb_model.predict(X_test)\n\n# Evaluate the model using Matthews correlation coefficient\nmcc = matthews_corrcoef(y_test, y_pred)\nprint(\"Matthews Correlation Coefficient:\", mcc)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:24:57.148126Z","iopub.execute_input":"2024-08-31T23:24:57.148430Z","iopub.status.idle":"2024-08-31T23:30:09.189424Z","shell.execute_reply.started":"2024-08-31T23:24:57.148399Z","shell.execute_reply":"2024-08-31T23:30:09.188434Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Matthews Correlation Coefficient: 0.9842937358629338\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"# Fit the model to the training data \nxgb_model.fit(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:30:09.190984Z","iopub.execute_input":"2024-08-31T23:30:09.191604Z","iopub.status.idle":"2024-08-31T23:31:43.806427Z","shell.execute_reply.started":"2024-08-31T23:30:09.191564Z","shell.execute_reply":"2024-08-31T23:31:43.805513Z"},"trusted":true},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.4, device='cuda', early_stopping_rounds=None,\n              enable_categorical=False, eval_metric='mlogloss',\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=14,\n              max_leaves=None, min_child_weight=1, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=3000,\n              n_jobs=None, num_parallel_tree=None, random_state=None, ...)","text/html":"<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.4, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=14,\n              max_leaves=None, min_child_weight=1, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=3000,\n              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.4, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=14,\n              max_leaves=None, min_child_weight=1, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=3000,\n              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"print(\"original data target distribution\")\nprint(df_train['class'].value_counts())\nprint(df_train['class'].value_counts() / len(df_train))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:31:43.807875Z","iopub.execute_input":"2024-08-31T23:31:43.808159Z","iopub.status.idle":"2024-08-31T23:31:44.520675Z","shell.execute_reply.started":"2024-08-31T23:31:43.808133Z","shell.execute_reply":"2024-08-31T23:31:44.519663Z"},"trusted":true},"outputs":[{"name":"stdout","text":"original data target distribution\nclass\np    1705396\ne    1411549\nName: count, dtype: int64\nclass\np    0.547137\ne    0.452863\nName: count, dtype: float64\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"result = pd.DataFrame(y_pred)\nprint(\"train result target label distribution\")\nprint(result[0].value_counts())\nprint(result[0].value_counts() / len(y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:31:44.521818Z","iopub.execute_input":"2024-08-31T23:31:44.522111Z","iopub.status.idle":"2024-08-31T23:31:44.550778Z","shell.execute_reply.started":"2024-08-31T23:31:44.522085Z","shell.execute_reply":"2024-08-31T23:31:44.549870Z"},"trusted":true},"outputs":[{"name":"stdout","text":"train result target label distribution\n0\n1    317736\n0    274485\nName: count, dtype: int64\n0\n1    0.536516\n0    0.463484\nName: count, dtype: float64\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"test_preds = xgb_model.predict(df_test_preprocessed)\ntest_preds = label_encoder.inverse_transform(test_preds)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:31:44.552173Z","iopub.execute_input":"2024-08-31T23:31:44.552431Z","iopub.status.idle":"2024-08-31T23:32:25.539308Z","shell.execute_reply.started":"2024-08-31T23:31:44.552408Z","shell.execute_reply":"2024-08-31T23:32:25.538325Z"},"trusted":true},"outputs":[],"execution_count":76},{"cell_type":"code","source":"result = pd.DataFrame(df_test['id'])\nresult['class'] = test_preds\nprint(\"test result target distribution\")\nprint(result['class'].value_counts())\nprint(result['class'].value_counts() / len(test_preds))","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:25.540656Z","iopub.execute_input":"2024-08-31T23:32:25.541038Z","iopub.status.idle":"2024-08-31T23:32:26.034659Z","shell.execute_reply.started":"2024-08-31T23:32:25.541004Z","shell.execute_reply":"2024-08-31T23:32:26.033609Z"},"trusted":true},"outputs":[{"name":"stdout","text":"test result target distribution\nclass\np    1133284\ne     944680\nName: count, dtype: int64\nclass\np    0.545382\ne    0.454618\nName: count, dtype: float64\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"prediction_data['internal_sub1'] = pd.DataFrame({'id': df_test['id'],\n                       'class': test_preds}).iloc[:,-1].values.flatten()\n\nprediction_data['internal_sub1'].head()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:26.035897Z","iopub.execute_input":"2024-08-31T23:32:26.036225Z","iopub.status.idle":"2024-08-31T23:32:26.092224Z","shell.execute_reply.started":"2024-08-31T23:32:26.036196Z","shell.execute_reply":"2024-08-31T23:32:26.091194Z"},"trusted":true},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"id\n3116945    e\n3116946    p\n3116947    p\n3116948    p\n3116949    e\nName: internal_sub1, dtype: object"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"# Autogluon with stack level=2, runtime= 15hours\n\"\"\"\nDue to memory error, this could not be run on Kaggle notebook environment. The result was generated\nfrom the local environment\n\nimport pandas as pd\nimport numpy as np  \nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns\nimport re\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport sklearn\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, FunctionTransformer, LabelEncoder, OneHotEncoder\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.ensemble import IsolationForest\n\ndf_train = pd.read_csv('train.csv')\ndf_test = pd.read_csv('test.csv')\n\ndf_train = df_train.drop(['id'], axis = 1)\ndf_test = df_test.drop(['id'], axis = 1)\n\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit and transform the target variable\ndf_train['class'] = label_encoder.fit_transform(df_train[['class']])\n\n# Install AutoGluon\n!conda install ray==2.10.0 --yes\n!conda install autogluon.tabular --yes\n!conda install ipywidgets --yes\n\nfrom autogluon.tabular import TabularPredictor\n# from autogluon.features.generators import FillNaFeatureGenerator\n\n## Map target values: 'e' -> 1, 'p' -> 0\nlabel = 'class'\n# train_data[label] = train_data[label].map({'e': 1, 'p': 0})\n\n# Train model with AutoGluon\npredictor = TabularPredictor(\n    label=label,\n    eval_metric='mcc',\n    problem_type='binary'\n).fit(\n    df_train,\n    presets='best_quality',\n    #feature_generator=feature_generator,  # Use the custom feature generator\n    time_limit=3600*15,\n    num_bag_folds=5,\n    verbosity=3,\n    excluded_model_types=['KNN'],\n    num_cpus = 'auto',\n    num_gpus = 'auto',\n    num_stack_levels = 2,  # enables the stacking of models\n    #hyperparameter_tune_kwargs='auto',\n)\n\n'''\nnum_stack_level\nNumber of stacking levels in stack ensemble. \nIncreases training time by approximately num_stack_levels+1. \nDefault is 0 (disabled). Recommended: 1-3 levels for better predictive performance. \nEnsure num_bag_folds ≥ 2 to avoid overfitting, or a ValueError will occur.\n'''\n\n# Print fit summary\nresults = predictor.fit_summary()\nprint(results)\n\ndf_test = pd.read_csv('test.csv')\n\n# Create a submission DataFrame\nsubmission = pd.DataFrame({\n    'id': df_test['id'],\n    'class': y_pred\n})\n\n# Save the predictions to a CSV file\nsubmission.to_csv('submission.csv', index=False)\n\n\"\"\"\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:26.094086Z","iopub.execute_input":"2024-08-31T23:32:26.094501Z","iopub.status.idle":"2024-08-31T23:32:26.107410Z","shell.execute_reply.started":"2024-08-31T23:32:26.094463Z","shell.execute_reply":"2024-08-31T23:32:26.106379Z"},"trusted":true},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"'\\nDue to memory error, this could not be run on Kaggle notebook environment. The result was generated\\nfrom the local environment\\n\\nimport pandas as pd\\nimport numpy as np  \\nimport matplotlib.pyplot as plt\\nfrom scipy import stats\\nimport seaborn as sns\\nimport re\\n\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\n\\nimport sklearn\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, FunctionTransformer, LabelEncoder, OneHotEncoder\\nfrom sklearn.metrics import matthews_corrcoef\\nfrom sklearn.ensemble import IsolationForest\\n\\ndf_train = pd.read_csv(\\'train.csv\\')\\ndf_test = pd.read_csv(\\'test.csv\\')\\n\\ndf_train = df_train.drop([\\'id\\'], axis = 1)\\ndf_test = df_test.drop([\\'id\\'], axis = 1)\\n\\n# Initialize LabelEncoder\\nlabel_encoder = LabelEncoder()\\n\\n# Fit and transform the target variable\\ndf_train[\\'class\\'] = label_encoder.fit_transform(df_train[[\\'class\\']])\\n\\n# Install AutoGluon\\n!conda install ray==2.10.0 --yes\\n!conda install autogluon.tabular --yes\\n!conda install ipywidgets --yes\\n\\nfrom autogluon.tabular import TabularPredictor\\n# from autogluon.features.generators import FillNaFeatureGenerator\\n\\n## Map target values: \\'e\\' -> 1, \\'p\\' -> 0\\nlabel = \\'class\\'\\n# train_data[label] = train_data[label].map({\\'e\\': 1, \\'p\\': 0})\\n\\n# Train model with AutoGluon\\npredictor = TabularPredictor(\\n    label=label,\\n    eval_metric=\\'mcc\\',\\n    problem_type=\\'binary\\'\\n).fit(\\n    df_train,\\n    presets=\\'best_quality\\',\\n    #feature_generator=feature_generator,  # Use the custom feature generator\\n    time_limit=3600*15,\\n    num_bag_folds=5,\\n    verbosity=3,\\n    excluded_model_types=[\\'KNN\\'],\\n    num_cpus = \\'auto\\',\\n    num_gpus = \\'auto\\',\\n    num_stack_levels = 2,  # enables the stacking of models\\n    #hyperparameter_tune_kwargs=\\'auto\\',\\n)\\n\\n\\'\\'\\'\\nnum_stack_level\\nNumber of stacking levels in stack ensemble. \\nIncreases training time by approximately num_stack_levels+1. \\nDefault is 0 (disabled). Recommended: 1-3 levels for better predictive performance. \\nEnsure num_bag_folds ≥ 2 to avoid overfitting, or a ValueError will occur.\\n\\'\\'\\'\\n\\n# Print fit summary\\nresults = predictor.fit_summary()\\nprint(results)\\n\\ndf_test = pd.read_csv(\\'test.csv\\')\\n\\n# Create a submission DataFrame\\nsubmission = pd.DataFrame({\\n    \\'id\\': df_test[\\'id\\'],\\n    \\'class\\': y_pred\\n})\\n\\n# Save the predictions to a CSV file\\nsubmission.to_csv(\\'submission.csv\\', index=False)\\n\\n'"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"prediction_data['internal_sub2'] = pd.read_csv(f\"/kaggle/input/autogluon-2stacklevel/submission.csv\").iloc[:,-1].values.flatten()\nprediction_data['internal_sub2'] = prediction_data['internal_sub2'].apply(lambda x: 'e' if x == 0 else 'p')\nprediction_data['internal_sub2'].head()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:26.108609Z","iopub.execute_input":"2024-08-31T23:32:26.108892Z","iopub.status.idle":"2024-08-31T23:32:27.229508Z","shell.execute_reply.started":"2024-08-31T23:32:26.108868Z","shell.execute_reply":"2024-08-31T23:32:27.228517Z"},"trusted":true},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"id\n3116945    e\n3116946    p\n3116947    p\n3116948    p\n3116949    e\nName: internal_sub2, dtype: object"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"prediction_data","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:27.230781Z","iopub.execute_input":"2024-08-31T23:32:27.231042Z","iopub.status.idle":"2024-08-31T23:32:27.245269Z","shell.execute_reply.started":"2024-08-31T23:32:27.231019Z","shell.execute_reply":"2024-08-31T23:32:27.244297Z"},"trusted":true},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"        sub1 sub2 sub3 sub4 sub5 internal_sub1 internal_sub2\nid                                                          \n3116945    e    e    e    e    e             e             e\n3116946    p    p    p    p    p             p             p\n3116947    p    p    p    p    p             p             p\n3116948    p    p    p    p    p             p             p\n3116949    e    e    e    e    e             e             e\n...      ...  ...  ...  ...  ...           ...           ...\n5194904    p    p    p    p    p             p             p\n5194905    p    p    p    p    p             p             p\n5194906    p    p    p    p    p             p             p\n5194907    e    e    e    e    e             e             e\n5194908    e    e    e    e    e             e             e\n\n[2077964 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sub1</th>\n      <th>sub2</th>\n      <th>sub3</th>\n      <th>sub4</th>\n      <th>sub5</th>\n      <th>internal_sub1</th>\n      <th>internal_sub2</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3116945</th>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n    </tr>\n    <tr>\n      <th>3116946</th>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>3116947</th>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>3116948</th>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>3116949</th>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5194904</th>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>5194905</th>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>5194906</th>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n      <td>p</td>\n    </tr>\n    <tr>\n      <th>5194907</th>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n    </tr>\n    <tr>\n      <th>5194908</th>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n      <td>e</td>\n    </tr>\n  </tbody>\n</table>\n<p>2077964 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"\nfor i in range(1, len(prediction_data.columns) - 1):\n    prediction_data[f\"sub{i}\"] = prediction_data[f\"sub{i}\"].apply(lambda x: 0 if x == 'e' else 1)\n\nfor i in range(1, 3):\n    prediction_data[f\"internal_sub{i}\"] = prediction_data[f\"internal_sub{i}\"].apply(lambda x: 0 if x == 'e' else 1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:27.246357Z","iopub.execute_input":"2024-08-31T23:32:27.246796Z","iopub.status.idle":"2024-08-31T23:32:36.636954Z","shell.execute_reply.started":"2024-08-31T23:32:27.246745Z","shell.execute_reply":"2024-08-31T23:32:36.636176Z"},"trusted":true},"outputs":[],"execution_count":82},{"cell_type":"code","source":"prediction_data","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:36.638200Z","iopub.execute_input":"2024-08-31T23:32:36.638486Z","iopub.status.idle":"2024-08-31T23:32:36.652917Z","shell.execute_reply.started":"2024-08-31T23:32:36.638461Z","shell.execute_reply":"2024-08-31T23:32:36.651985Z"},"trusted":true},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"         sub1  sub2  sub3  sub4  sub5  internal_sub1  internal_sub2\nid                                                                 \n3116945     0     0     0     0     0              0              0\n3116946     1     1     1     1     1              1              1\n3116947     1     1     1     1     1              1              1\n3116948     1     1     1     1     1              1              1\n3116949     0     0     0     0     0              0              0\n...       ...   ...   ...   ...   ...            ...            ...\n5194904     1     1     1     1     1              1              1\n5194905     1     1     1     1     1              1              1\n5194906     1     1     1     1     1              1              1\n5194907     0     0     0     0     0              0              0\n5194908     0     0     0     0     0              0              0\n\n[2077964 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sub1</th>\n      <th>sub2</th>\n      <th>sub3</th>\n      <th>sub4</th>\n      <th>sub5</th>\n      <th>internal_sub1</th>\n      <th>internal_sub2</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3116945</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3116946</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3116947</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3116948</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3116949</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5194904</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5194905</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5194906</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5194907</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5194908</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2077964 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":83},{"cell_type":"markdown","source":"The SHAP representation from XGBoost only shows the strongest feature impact with the stem-width while the rest of them captures the strongest feature impact with the gill-attachment. \n\nUnder the hypothesis that XGBoost captures slightly different patterns from the dataset, the weight for XGBoost has been given significantly higher than the rest of the models whose strongest feature impact is gill-attachment.","metadata":{}},{"cell_type":"code","source":"weights = [0, 0, 0, 0, 0, 6, 0]\n\nfor i in range(1, len(prediction_data.columns) - 1):\n    prediction_data[f\"sub{i}\"] = prediction_data[f\"sub{i}\"] * weights[i - 1]\n\nfor i in range(1, 3):\n    prediction_data[f\"internal_sub{i}\"] = prediction_data[f\"internal_sub{i}\"] * weights[i + 4]","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:36.653905Z","iopub.execute_input":"2024-08-31T23:32:36.654170Z","iopub.status.idle":"2024-08-31T23:32:36.693523Z","shell.execute_reply.started":"2024-08-31T23:32:36.654130Z","shell.execute_reply":"2024-08-31T23:32:36.692616Z"},"trusted":true},"outputs":[],"execution_count":84},{"cell_type":"code","source":"prediction_data","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:36.694712Z","iopub.execute_input":"2024-08-31T23:32:36.695051Z","iopub.status.idle":"2024-08-31T23:32:36.709300Z","shell.execute_reply.started":"2024-08-31T23:32:36.695021Z","shell.execute_reply":"2024-08-31T23:32:36.708330Z"},"trusted":true},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"         sub1  sub2  sub3  sub4  sub5  internal_sub1  internal_sub2\nid                                                                 \n3116945     0     0     0     0     0              0              0\n3116946     0     0     0     0     0              6              0\n3116947     0     0     0     0     0              6              0\n3116948     0     0     0     0     0              6              0\n3116949     0     0     0     0     0              0              0\n...       ...   ...   ...   ...   ...            ...            ...\n5194904     0     0     0     0     0              6              0\n5194905     0     0     0     0     0              6              0\n5194906     0     0     0     0     0              6              0\n5194907     0     0     0     0     0              0              0\n5194908     0     0     0     0     0              0              0\n\n[2077964 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sub1</th>\n      <th>sub2</th>\n      <th>sub3</th>\n      <th>sub4</th>\n      <th>sub5</th>\n      <th>internal_sub1</th>\n      <th>internal_sub2</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3116945</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3116946</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3116947</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3116948</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3116949</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5194904</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5194905</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5194906</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5194907</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5194908</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2077964 rows × 7 columns</p>\n</div>"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\noutput = pd.DataFrame(prediction_data.sum(axis = 1).tolist(), columns = ['class'])\nprint(output)\nmin_max_scaler = MinMaxScaler()\nfitted = min_max_scaler.fit(output)\n\noutput = min_max_scaler.transform(output)\noutput_df = pd.DataFrame(prediction_data.index, columns = ['id'])\noutput_df['class'] = output\nprint(output_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:36.710585Z","iopub.execute_input":"2024-08-31T23:32:36.710899Z","iopub.status.idle":"2024-08-31T23:32:38.170462Z","shell.execute_reply.started":"2024-08-31T23:32:36.710876Z","shell.execute_reply":"2024-08-31T23:32:38.169446Z"},"trusted":true},"outputs":[{"name":"stdout","text":"         class\n0            0\n1            6\n2            6\n3            6\n4            0\n...        ...\n2077959      6\n2077960      6\n2077961      6\n2077962      0\n2077963      0\n\n[2077964 rows x 1 columns]\n        id  class\n0  3116945    0.0\n1  3116946    1.0\n2  3116947    1.0\n3  3116948    1.0\n4  3116949    0.0\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"output_df['class'] = output_df['class'].apply(lambda x: 'e' if x < 0.5 else 'p')\noutput_df['class'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:38.172011Z","iopub.execute_input":"2024-08-31T23:32:38.172373Z","iopub.status.idle":"2024-08-31T23:32:38.995675Z","shell.execute_reply.started":"2024-08-31T23:32:38.172340Z","shell.execute_reply":"2024-08-31T23:32:38.994739Z"},"trusted":true},"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"array(['e', 'p'], dtype=object)"},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"len(output_df[output_df['class'] == 'e']) / len(output_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:38.996958Z","iopub.execute_input":"2024-08-31T23:32:38.997334Z","iopub.status.idle":"2024-08-31T23:32:39.364448Z","shell.execute_reply.started":"2024-08-31T23:32:38.997298Z","shell.execute_reply":"2024-08-31T23:32:39.363499Z"},"trusted":true},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"0.4546180780802747"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\noutput = pd.DataFrame(prediction_data.sum(axis = 1).tolist(), columns = ['class'])\n\nscaler = StandardScaler()\n\noutput_df = pd.DataFrame(prediction_data.index, columns = ['id'])\noutput_df['class'] = pd.DataFrame(scaler.fit_transform(output), columns = ['class'])\noutput_df['class'] = output_df['class'].apply(lambda x: 'e' if x < 0 else 'p')\nlen(output_df[output_df['class'] == 'e']) / len(output_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:39.365443Z","iopub.execute_input":"2024-08-31T23:32:39.365721Z","iopub.status.idle":"2024-08-31T23:32:41.940987Z","shell.execute_reply.started":"2024-08-31T23:32:39.365685Z","shell.execute_reply":"2024-08-31T23:32:41.939834Z"},"trusted":true},"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"0.4546180780802747"},"metadata":{}}],"execution_count":89},{"cell_type":"code","source":"%%time \noutput_df.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T23:32:41.942757Z","iopub.execute_input":"2024-08-31T23:32:41.943167Z","iopub.status.idle":"2024-08-31T23:32:44.348554Z","shell.execute_reply.started":"2024-08-31T23:32:41.943131Z","shell.execute_reply":"2024-08-31T23:32:44.347633Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 2.35 s, sys: 55 ms, total: 2.4 s\nWall time: 2.4 s\n","output_type":"stream"}],"execution_count":90}]}